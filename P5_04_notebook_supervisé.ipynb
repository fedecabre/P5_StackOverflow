{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc3bee7",
   "metadata": {},
   "source": [
    "Dans ce notebook nous allons analyser la base de donées des post Python et R pour un\n",
    "entrainement de modèles supervisés.\n",
    "\n",
    "Nous allons commencer avec un modèle KNN, puis RandomForest et un Multi Layer Perceptron\n",
    "pour une classification entre les posts Python et R, nous allons utiliser plusieurs tags par post\n",
    "avec la strategie One vs All\n",
    "\n",
    "Une fois le modèle entrainé nous allons comparer leurs scores F1 et choisir le meilleur pour\n",
    "l'utiliser dans notre API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce7668",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdfef178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T15:39:30.889268Z",
     "start_time": "2021-06-03T15:39:30.881106Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.display import display\n",
    "import pickle # pour exporter les modèles entrainés\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2dbaef",
   "metadata": {},
   "source": [
    "# Importation des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b8e2d2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T15:40:45.473647Z",
     "start_time": "2021-06-03T15:40:45.430867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "text/plain": "         Id                          Title  \\\n0  10679131   change order array dimension   \n1   1169714  difference r program language   \n2   8096313          bind note r cmd check   \n3    526457     form fail validation field   \n4  10437442      place border around point   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Body  \\\n0                                                                                                                                                                                                                                                                                                                                               reorder dimension n array example three array sale data first dimension represent date dimension store dimension department transform array dimension store department date example hop solution   \n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   difference r   \n2                                                                                                                                                                  check package obtain note bind use function like subset use name element argument example data frame dataframeactruefalsetrueb silly thing like subsetfooa transformfooab work expect code check r cmd however refer element complains binding variable work ok really notes package prefer pas check error warn note also really rework code way cod argument refer variable   \n3  model define class articlemodelsmodel slug modelsslugfieldmaxlength title modelscharfieldmaxlength form class articleformmodelform class meta model article validation fail try exist row requestmethod post form articleformrequestpost poof formsave create entry fine however try field validation longer pass error property nothing drop within gut saw article none already exist look like fails value check want row form validation look like something figure run django croak basemodelformvalidateunique call form initialization   \n4                                                                  would like place border around point scatterplot fill base data use ggplot also would like legend entry border since point basically look plot border around point df dataframeidrunif x yrunif ggplotdf aesxx size bonus would like entry border try df dataframeidrunif x yrunif ggplotdf aesxx colourblack size give understand give education ggplot understand seem map fill color anything help perhaps get fill map right use hack like one hte set figure turn legend   \n\n                        Tags  Score  \\\n0   r multidimensional-array     38   \n1  r programming-languages s     22   \n2                  r package     43   \n3              python django     20   \n4                  r ggplot2     57   \n\n                                                                   Title_raw  \\\n0                                    How to change order of array dimensions   \n1  What are the major differences between the R and S programming languages?   \n2                 No visible binding for global variable Note in R CMD check   \n3                             Django form fails validation on a unique field   \n4                                               Place a border around points   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Text  \n0                                                                                                                                                                                                                                                                                                                                             change order array dimension reorder dimension n array example three array sale data first dimension represent date dimension store dimension department transform array dimension store department date example hop solution  \n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                difference r program language difference r  \n2                                                                                                                                                                       bind note r cmd check check package obtain note bind use function like subset use name element argument example data frame dataframeactruefalsetrueb silly thing like subsetfooa transformfooab work expect code check r cmd however refer element complains binding variable work ok really notes package prefer pas check error warn note also really rework code way cod argument refer variable  \n3  form fail validation field model define class articlemodelsmodel slug modelsslugfieldmaxlength title modelscharfieldmaxlength form class articleformmodelform class meta model article validation fail try exist row requestmethod post form articleformrequestpost poof formsave create entry fine however try field validation longer pass error property nothing drop within gut saw article none already exist look like fails value check want row form validation look like something figure run django croak basemodelformvalidateunique call form initialization  \n4                                                                   place border around point would like place border around point scatterplot fill base data use ggplot also would like legend entry border since point basically look plot border around point df dataframeidrunif x yrunif ggplotdf aesxx size bonus would like entry border try df dataframeidrunif x yrunif ggplotdf aesxx colourblack size give understand give education ggplot understand seem map fill color anything help perhaps get fill map right use hack like one hte set figure turn legend  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Title</th>\n      <th>Body</th>\n      <th>Tags</th>\n      <th>Score</th>\n      <th>Title_raw</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10679131</td>\n      <td>change order array dimension</td>\n      <td>reorder dimension n array example three array sale data first dimension represent date dimension store dimension department transform array dimension store department date example hop solution</td>\n      <td>r multidimensional-array</td>\n      <td>38</td>\n      <td>How to change order of array dimensions</td>\n      <td>change order array dimension reorder dimension n array example three array sale data first dimension represent date dimension store dimension department transform array dimension store department date example hop solution</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1169714</td>\n      <td>difference r program language</td>\n      <td>difference r</td>\n      <td>r programming-languages s</td>\n      <td>22</td>\n      <td>What are the major differences between the R and S programming languages?</td>\n      <td>difference r program language difference r</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8096313</td>\n      <td>bind note r cmd check</td>\n      <td>check package obtain note bind use function like subset use name element argument example data frame dataframeactruefalsetrueb silly thing like subsetfooa transformfooab work expect code check r cmd however refer element complains binding variable work ok really notes package prefer pas check error warn note also really rework code way cod argument refer variable</td>\n      <td>r package</td>\n      <td>43</td>\n      <td>No visible binding for global variable Note in R CMD check</td>\n      <td>bind note r cmd check check package obtain note bind use function like subset use name element argument example data frame dataframeactruefalsetrueb silly thing like subsetfooa transformfooab work expect code check r cmd however refer element complains binding variable work ok really notes package prefer pas check error warn note also really rework code way cod argument refer variable</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>526457</td>\n      <td>form fail validation field</td>\n      <td>model define class articlemodelsmodel slug modelsslugfieldmaxlength title modelscharfieldmaxlength form class articleformmodelform class meta model article validation fail try exist row requestmethod post form articleformrequestpost poof formsave create entry fine however try field validation longer pass error property nothing drop within gut saw article none already exist look like fails value check want row form validation look like something figure run django croak basemodelformvalidateunique call form initialization</td>\n      <td>python django</td>\n      <td>20</td>\n      <td>Django form fails validation on a unique field</td>\n      <td>form fail validation field model define class articlemodelsmodel slug modelsslugfieldmaxlength title modelscharfieldmaxlength form class articleformmodelform class meta model article validation fail try exist row requestmethod post form articleformrequestpost poof formsave create entry fine however try field validation longer pass error property nothing drop within gut saw article none already exist look like fails value check want row form validation look like something figure run django croak basemodelformvalidateunique call form initialization</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10437442</td>\n      <td>place border around point</td>\n      <td>would like place border around point scatterplot fill base data use ggplot also would like legend entry border since point basically look plot border around point df dataframeidrunif x yrunif ggplotdf aesxx size bonus would like entry border try df dataframeidrunif x yrunif ggplotdf aesxx colourblack size give understand give education ggplot understand seem map fill color anything help perhaps get fill map right use hack like one hte set figure turn legend</td>\n      <td>r ggplot2</td>\n      <td>57</td>\n      <td>Place a border around points</td>\n      <td>place border around point would like place border around point scatterplot fill base data use ggplot also would like legend entry border since point basically look plot border around point df dataframeidrunif x yrunif ggplotdf aesxx size bonus would like entry border try df dataframeidrunif x yrunif ggplotdf aesxx colourblack size give understand give education ggplot understand seem map fill color anything help perhaps get fill map right use hack like one hte set figure turn legend</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtypes_questions = {'Id':'int32', 'Score': 'int16', 'Title': 'str',\n",
    "                    'Body': 'str', 'Title_raw': 'str', 'Text': 'str',\n",
    "                    'Tags': 'str'}\n",
    "\n",
    "nrows = 20000\n",
    "\n",
    "df_questions = pd.read_csv('df_questions_fullclean.csv',\n",
    "                           usecols=dtypes_questions.keys(),\n",
    "                           encoding = \"utf-8\",\n",
    "                           dtype=dtypes_questions,\n",
    "                           nrows=nrows\n",
    "                          )\n",
    "\n",
    "print(len(df_questions))\n",
    "display(df_questions.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47355cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of text_train: <class 'pandas.core.series.Series'>\n",
      "length of text_train: 2000\n",
      "text_train[6]:\n",
      "way list name python module package way list name modules package without use example give package testpkg testpkginitpy testpkgmoduleapy testpkgmodulebpy wonder builtin way something like modulea moduleb approach would iterate module search path order find package directory one could list file filter uniquelynamed file strip extension return list seem like amount work something import mechanism already internally functionality expose anywhere\n"
     ]
    }
   ],
   "source": [
    "# création des labels python et r\n",
    "text_train, tag_train = df_questions.Text, df_questions.Tags\n",
    "print(\"type of text_train: {}\".format(type(text_train)))\n",
    "print(\"length of text_train: {}\".format(len(text_train)))\n",
    "print(\"text_train[6]:\\n{}\".format(text_train[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.series.Series"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.series.Series"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tag_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# ajouter les fichiers pour test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Répresenter les données textuelles comme un bag-of-words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<2000x11756 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 61287 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect_X = CountVectorizer().fit(text_train)\n",
    "X_train = vect_X.transform(text_train)\n",
    "\n",
    "pickle.dump(vect_X, open('API/models/vect_X.pickle', 'wb')) # enregistre le modeèle de transformation X\n",
    "\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 11756\n",
      "First 20 features:\n",
      "['aa', 'aaa', 'aaaaa', 'aaaarghxxx', 'aaardvark', 'aaaxxx', 'aabbcdefg', 'aabsiddfdfdatatg', 'aacute', 'aardvark', 'aavec', 'aazqmaso', 'ab', 'abbrach', 'abbreche', 'abbreviation', 'abc', 'abca', 'abcabcdefabcd', 'abcdc']\n",
      "Features 20010 to 20030:\n",
      "[]\n",
      "Every 2000th feature:\n",
      "['aa', 'counter', 'functionlm', 'lstlengthlst', 'promise', 'striph']\n"
     ]
    }
   ],
   "source": [
    "feature_names_X = vect_X.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names_X)))\n",
    "print(\"First 20 features:\\n{}\".format(feature_names_X[:20]))\n",
    "print(\"Features 20010 to 20030:\\n{}\".format(feature_names_X[20010:20030]))\n",
    "print(\"Every 2000th feature:\\n{}\".format(feature_names_X[::2000]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train:\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "vect_Y = CountVectorizer(binary=True, max_features=None, token_pattern= \"(?u)\\\\b\\\\w+\\\\b\").fit(tag_train)\n",
    "# nous avons laissé l'option binary true car il est inutile d'avoir plus d'une fois le même token\n",
    "# nous allons limiter le nombre de de features car le F1 Score avec tous les tags pour le modèle KNN est 0.013\n",
    "# avec 10 features nous arrivons à un F1 Score de 37,8%\n",
    "# On utilise un token_pattern different pour pouvoir récupérer le tag r\n",
    "Y_train = vect_Y.transform(tag_train).toarray()\n",
    "\n",
    "pickle.dump(vect_Y, open('API/models/vect_Y.pickle', 'wb')) # enregistre le modèle de transformation Y\n",
    "\n",
    "print(\"Y_train:\\n{}\".format(repr(Y_train)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1151\n",
      "First 20 features:\n",
      "['2', '2008', '2to3', '3', '3d', '4', '404', '5', '6', '7', '8', 'access', 'accuracy', 'active', 'address', 'admin', 'administration', 'aes', 'agent', 'aggregate']\n",
      "Features 210 to 230:\n",
      "['pyrserve', 'python', 'pytz', 'pywin32', 'qt', 'quantmod', 'queryset', 'queue', 'quotes', 'r', 'random', 'range', 'rapydscript', 'raster', 'ratio', 'rawstring', 'rbind', 'rcpp', 'rdata', 'rdbms']\n",
      "Every 200th feature:\n",
      "['2', 'css', 'global', 'migration', 'pyrserve', 'tab']\n"
     ]
    }
   ],
   "source": [
    "feature_names_Y = vect_Y.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names_Y)))\n",
    "print(\"First 20 features:\\n{}\".format(feature_names_Y[:20]))\n",
    "print(\"Features 210 to 230:\\n{}\".format(feature_names_Y[800:820]))\n",
    "print(\"Every 200th feature:\\n{}\".format(feature_names_Y[::200]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, Y_train)\n",
    "\n",
    "pickle.dump(knn_clf, open('API/models/knn_clf.pickle', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def text_preciction_labels(new_post,vect_X,vect_Y,model,df_questions):\n",
    "    feature_names_Y = vect_Y.get_feature_names() # liste des tags\n",
    "    Y_train = vect_Y.transform(df_questions.Tags) # liste des listes des Tags par post\n",
    "    new_post_vect = vect_X.transform([new_post]) # vectorisation du nouveau post pour prediction du modèle\n",
    "    y_predict = model.predict(new_post_vect) # prediction du modèle entrainé\n",
    "\n",
    "    tags = np.argsort(y_predict[0,:])[::-1][:10].tolist()\n",
    "    scores = np.sort(y_predict[0,:])[::-1][:10]\n",
    "\n",
    "    print(df_questions.Title_raw[id_sample],'\\n')\n",
    "    print(df_questions.Body[id_sample],'\\n')\n",
    "    print(df_questions.Text[id_sample])\n",
    "    print('\\n','Tags prediction : ', '\\n')\n",
    "    for tag,score in zip(tags,scores) :\n",
    "        if score > 0  :\n",
    "            print(feature_names_Y[tag],score)\n",
    "    print('\\n','Tags labels : ','\\n')\n",
    "    y_labels = Y_train[id_sample].toarray()\n",
    "    tags = np.argsort(y_labels[0,:])[::-1][:10].tolist()\n",
    "    scores = np.sort(y_labels[0,:])[::-1][:10]\n",
    "    for tag,score in zip(tags,scores) :\n",
    "        if score > 0  :\n",
    "            print(feature_names_Y[tag],score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Coverage and Unit Testing of Python Code \n",
      "\n",
      "already visit python unittesting framework look unit test framework also coverage respect unit test far come across coveragepy better option interest option integrate cpython unit test code code coverage python code studio plugins something ironpython studio do achieve look suggestion \n",
      "\n",
      "code coverage unit test python code already visit python unittesting framework look unit test framework also coverage respect unit test far come across coveragepy better option interest option integrate cpython unit test code code coverage python code studio plugins something ironpython studio do achieve look suggestion\n",
      "\n",
      " Tags prediction :  \n",
      "\n",
      "python 1\n",
      "\n",
      " Tags labels :  \n",
      "\n",
      "code 1\n",
      "unit 1\n",
      "studio 1\n",
      "visual 1\n",
      "coverage 1\n",
      "testing 1\n",
      "python 1\n",
      "2008 1\n"
     ]
    }
   ],
   "source": [
    "id_sample = 50\n",
    "new_post = text_train[id_sample]\n",
    "text_preciction_labels(new_post,vect_X,vect_Y,knn_clf,df_questions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cross validation du modèle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.9 s, sys: 90.7 ms, total: 52 s\n",
      "Wall time: 51.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 50 secondes pour calculer 2000 lignes\n",
    "# 15min 57s pour 20 000 lignes\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, Y_train, cv=3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "0.004908140130484893"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_train_knn_pred_ones = (y_train_knn_pred >0).astype(int)\n",
    "f1_score(Y_train, y_train_knn_pred_ones, average=\"macro\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création d'une pipeline pour choisir le meilleurs parametre pour ce modèle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.68\n",
      "Best parameters:  {'n_neighbors': 128}\n",
      "Best nombre de features:  2\n",
      "['python', 'r'] \n",
      "\n",
      "Best cross-validation score: 0.65\n",
      "Best parameters:  {'n_neighbors': 128}\n",
      "Best nombre de features:  4\n",
      "['django', 'ggplot2', 'python', 'r'] \n",
      "\n",
      "Best cross-validation score: 0.62\n",
      "Best parameters:  {'n_neighbors': 128}\n",
      "Best nombre de features:  6\n",
      "['dataframe', 'django', 'faq', 'ggplot2', 'python', 'r'] \n",
      "\n",
      "Best cross-validation score: 0.55\n",
      "Best parameters:  {'n_neighbors': 8}\n",
      "Best nombre de features:  8\n",
      "['dataframe', 'django', 'faq', 'ggplot2', 'list', 'python', 'r', 'string'] \n",
      "\n",
      "Best cross-validation score: 0.48\n",
      "Best parameters:  {'n_neighbors': 8}\n",
      "Best nombre de features:  16\n",
      "['c', 'data', 'dataframe', 'django', 'faq', 'file', 'ggplot2', 'list', 'matrix', 'plot', 'python', 'r', 'regex', 'statistics', 'string', 'windows'] \n",
      "\n",
      "Best cross-validation score: 0.41\n",
      "Best parameters:  {'n_neighbors': 8}\n",
      "Best nombre de features:  32\n",
      "['c', 'class', 'data', 'dataframe', 'date', 'datetime', 'dictionary', 'django', 'exception', 'faq', 'file', 'function', 'ggplot2', 'list', 'matrix', 'memory', 'models', 'oop', 'performance', 'plot', 'python', 'r', 'regex', 'statistics', 'string', 'table', 'time', 'unicode', 'vector', 'windows', 'x', 'xml'] \n",
      "\n",
      "CPU times: user 28.9 s, sys: 42.6 ms, total: 28.9 s\n",
      "Wall time: 28.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 6min 42s pour 20 000 post\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_neighbors' : [6, 8,32,64,128,255,500]}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='f1_micro')\n",
    "\n",
    "best_score = 0\n",
    "best_param = {}\n",
    "best_feature_number = 0\n",
    "\n",
    "for i in [2,4,6,8,16,32]:\n",
    "    vect_Y = CountVectorizer(binary=True, token_pattern= \"(?u)\\\\b\\\\w+\\\\b\", max_features=i).fit(tag_train)\n",
    "    Y_train = vect_Y.transform(text_train).toarray()\n",
    "    grid.fit(X_train, Y_train)\n",
    "    #if grid.best_score_>best_score:\n",
    "    best_score = grid.best_score_\n",
    "    best_param = grid.best_params_\n",
    "    best_feature_number = i\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(best_score))\n",
    "    print(\"Best parameters: \", best_param)\n",
    "    print(\"Best nombre de features: \", best_feature_number)\n",
    "    print(vect_Y.get_feature_names(),'\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R define dimensions of empty data frame \n",
      "\n",
      "try collect data subset data set need create data frame collect result problem know create data frame define number column without actually data put c would like create df w column id max min collectid s subsetdf dfid collectmax maxssvalue collectmin minssvalue feel ask question almost feel like ask find would greatly appreciate help \n",
      "\n",
      "r define dimension empty data frame try collect data subset data set need create data frame collect result problem know create data frame define number column without actually data put c would like create df w column id max min collectid s subsetdf dfid collectmax maxssvalue collectmin minssvalue feel ask question almost feel like ask find would greatly appreciate help\n",
      "\n",
      " Tags prediction :  \n",
      "\n",
      "data 1\n",
      "\n",
      " Tags labels :  \n",
      "\n",
      "r 1\n"
     ]
    }
   ],
   "source": [
    "KNNmodel = grid.best_estimator_\n",
    "\n",
    "id_sample = 1002\n",
    "new_post = text_train[id_sample]\n",
    "text_preciction_labels(new_post,vect_X,vect_Y,KNNmodel,df_questions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### pour 20 000 post\n",
    "Cross validation CV=5\n",
    "KNeighborsClassifier(), param_grid, cv=5, scoring='f1_micro')\n",
    "\n",
    "Best cross-validation score: 0.78\n",
    "Best parameters:  {'n_neighbors': 255}\n",
    "Best nombre de features:  2\n",
    "['python', 'r']\n",
    "\n",
    "Best cross-validation score: 0.75\n",
    "Best parameters:  {'n_neighbors': 255}\n",
    "Best nombre de features:  4\n",
    "['django', 'ggplot2', 'python', 'r']\n",
    "\n",
    "Best cross-validation score: 0.71\n",
    "Best parameters:  {'n_neighbors': 64}\n",
    "Best nombre de features:  6\n",
    "['django', 'ggplot2', 'list', 'numpy', 'python', 'r']\n",
    "\n",
    "Best cross-validation score: 0.66\n",
    "Best parameters:  {'n_neighbors': 32}\n",
    "Best nombre de features:  8\n",
    "['dataframe', 'django', 'ggplot2', 'list', 'numpy', 'python', 'r', 'string']\n",
    "\n",
    "Best cross-validation score: 0.57\n",
    "Best parameters:  {'n_neighbors': 32}\n",
    "Best nombre de features:  16\n",
    "['2', '3', 'data', 'dataframe', 'dictionary', 'django', 'ggplot2', 'list', 'matplotlib', 'numpy', 'pandas', 'python', 'r', 'regex', 'string', 'x']\n",
    "\n",
    "Best cross-validation score: 0.50\n",
    "Best parameters:  {'n_neighbors': 8}\n",
    "Best nombre de features:  32\n",
    "['2', '3', '7', 'class', 'data', 'dataframe', 'datetime', 'dictionary', 'django', 'dplyr', 'faq', 'file', 'flask', 'function', 'ggplot2', 'import', 'list', 'matplotlib', 'models', 'numpy', 'pandas', 'performance', 'plot', 'python', 'r', 'regex', 'scipy', 'sqlalchemy', 'string', 'table', 'testing', 'x']\n",
    "\n",
    "CPU times: user 6min 17s, sys: 28.4 s, total: 6min 45s\n",
    "Wall time: 6min 45s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.76\n",
      "Best parameters:  {'n_estimators': 500}\n",
      "Best nombre de features:  2\n",
      "['python', 'r'] \n",
      "\n",
      "Best cross-validation score: 0.75\n",
      "Best parameters:  {'n_estimators': 1000}\n",
      "Best nombre de features:  4\n",
      "['django', 'ggplot2', 'python', 'r'] \n",
      "\n",
      "Best cross-validation score: 0.69\n",
      "Best parameters:  {'n_estimators': 1000}\n",
      "Best nombre de features:  8\n",
      "['dataframe', 'django', 'faq', 'ggplot2', 'list', 'python', 'r', 'string'] \n",
      "\n",
      "Best cross-validation score: 0.65\n",
      "Best parameters:  {'n_estimators': 1000}\n",
      "Best nombre de features:  16\n",
      "['c', 'data', 'dataframe', 'django', 'faq', 'file', 'ggplot2', 'list', 'matrix', 'plot', 'python', 'r', 'regex', 'statistics', 'string', 'windows'] \n",
      "\n",
      "Best cross-validation score: 0.55\n",
      "Best parameters:  {'n_estimators': 1000}\n",
      "Best nombre de features:  32\n",
      "['c', 'class', 'data', 'dataframe', 'date', 'datetime', 'dictionary', 'django', 'exception', 'faq', 'file', 'function', 'ggplot2', 'list', 'matrix', 'memory', 'models', 'oop', 'performance', 'plot', 'python', 'r', 'regex', 'statistics', 'string', 'table', 'time', 'unicode', 'vector', 'windows', 'x', 'xml'] \n",
      "\n",
      "CPU times: user 12min 49s, sys: 1.32 s, total: 12min 50s\n",
      "Wall time: 12min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 4h 32min 57s pour 20 000 posts\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {'n_estimators' : [100,500,1000],\n",
    "              }\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='f1_micro')\n",
    "\n",
    "best_score = 0\n",
    "best_param = {}\n",
    "best_feature_number = 0\n",
    "\n",
    "for i in [2,4,8,16,32]:\n",
    "    vect_Y = CountVectorizer(binary=True, token_pattern= \"(?u)\\\\b\\\\w+\\\\b\", max_features=i).fit(tag_train)\n",
    "    Y_train = vect_Y.transform(text_train).toarray()\n",
    "    grid.fit(X_train, Y_train)\n",
    "    #if grid.best_score_>best_score:\n",
    "    best_score = grid.best_score_\n",
    "    best_param = grid.best_params_\n",
    "    best_feature_number = i\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(best_score))\n",
    "    print(\"Best parameters: \", best_param)\n",
    "    print(\"Best nombre de features: \", best_feature_number)\n",
    "    print(vect_Y.get_feature_names(),'\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "RandomForestmodel = grid.best_estimator_\n",
    "\n",
    "id_sample = 1002\n",
    "new_post = text_train[id_sample]\n",
    "text_preciction_labels(new_post,vect_X,vect_Y,RandomForestmodel,df_questions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R define dimensions of empty data frame \n",
      "\n",
      "try collect data subset data set need create data frame collect result problem know create data frame define number column without actually data put c would like create df w column id max min collectid s subsetdf dfid collectmax maxssvalue collectmin minssvalue feel ask question almost feel like ask find would greatly appreciate help \n",
      "\n",
      "r define dimension empty data frame try collect data subset data set need create data frame collect result problem know create data frame define number column without actually data put c would like create df w column id max min collectid s subsetdf dfid collectmax maxssvalue collectmin minssvalue feel ask question almost feel like ask find would greatly appreciate help\n",
      "\n",
      " Tags prediction :  \n",
      "\n",
      "c 1\n",
      "data 1\n",
      "r 1\n",
      "\n",
      " Tags labels :  \n",
      "\n",
      "r 1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### pour 20 000 post\n",
    "Cross validation CV=5\n",
    "RandomForestClassifier(), param_grid, cv=5, scoring='f1_micro')\n",
    "\n",
    "Best cross-validation score: 0.83\n",
    "Best parameters:  {'n_estimators': 1000}\n",
    "Best nombre de features:  2\n",
    "['python', 'r']\n",
    "\n",
    "Best cross-validation score: 0.82\n",
    "Best parameters:  {'n_estimators': 500}\n",
    "Best nombre de features:  4\n",
    "['django', 'ggplot2', 'python', 'r']\n",
    "\n",
    "Best cross-validation score: 0.75\n",
    "Best parameters:  {'n_estimators': 1000}\n",
    "Best nombre de features:  8\n",
    "['dataframe', 'django', 'ggplot2', 'list', 'numpy', 'python', 'r', 'string']\n",
    "\n",
    "Best cross-validation score: 0.67\n",
    "Best parameters:  {'n_estimators': 100}\n",
    "Best nombre de features:  16\n",
    "['2', '3', 'data', 'dataframe', 'dictionary', 'django', 'ggplot2', 'list', 'matplotlib', 'numpy', 'pandas', 'python', 'r', 'regex', 'string', 'x']\n",
    "\n",
    "Best cross-validation score: 0.58\n",
    "Best parameters:  {'n_estimators': 100}\n",
    "Best nombre de features:  32\n",
    "['2', '3', '7', 'class', 'data', 'dataframe', 'datetime', 'dictionary', 'django', 'dplyr', 'faq', 'file', 'flask', 'function', 'ggplot2', 'import', 'list', 'matplotlib', 'models', 'numpy', 'pandas', 'performance', 'plot', 'python', 'r', 'regex', 'scipy', 'sqlalchemy', 'string', 'table', 'testing', 'x']\n",
    "\n",
    "CPU times: user 4h 32min 40s, sys: 16 s, total: 4h 32min 56s\n",
    "Wall time: 4h 32min 57s"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multilayer Perceptron classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# 2d 7h 36min 50s pour 20 000 posts\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {'alpha' : [0.001,0.01,0.1],\n",
    "              'learning_rate_init' : [0.0001,0.001,0.01] }\n",
    "grid = RandomizedSearchCV(MLPClassifier(max_iter=500), param_grid, cv=5, scoring='f1_micro')\n",
    "\n",
    "best_score = 0\n",
    "best_param = {}\n",
    "best_feature_number = 0\n",
    "\n",
    "for i in [2,4,8,16,32]:\n",
    "    vect_Y = CountVectorizer(binary=True, token_pattern= \"(?u)\\\\b\\\\w+\\\\b\", max_features=i).fit(tag_train)\n",
    "    Y_train = vect_Y.transform(text_train).toarray()\n",
    "    grid.fit(X_train, Y_train)\n",
    "    #if grid.best_score_>best_score:\n",
    "    best_score = grid.best_score_\n",
    "    best_param = grid.best_params_\n",
    "    best_feature_number = i\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(best_score))\n",
    "    print(\"Best parameters: \", best_param)\n",
    "    print(\"Best nombre de features: \", best_feature_number)\n",
    "    print(vect_Y.get_feature_names(),'\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 38s, sys: 9.6 s, total: 16min 47s\n",
      "Wall time: 2min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": "MLPClassifier(alpha=0.1, learning_rate_init=0.0001, max_iter=1500)"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "MLP_clf = MLPClassifier(max_iter=1500, alpha=0.1, learning_rate_init=0.0001)\n",
    "# la convergence du modèle n'est pas encore faite à 1000 itérations\n",
    "vect_Y_32 = CountVectorizer(binary=True, token_pattern= \"(?u)\\\\b\\\\w+\\\\b\", max_features=32).fit(tag_train)\n",
    "Y_train = vect_Y_32.transform(tag_train).toarray()\n",
    "MLP_clf.fit(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "pickle.dump(vect_Y_32, open('API/models/vect_Y_32.pickle', 'wb'))\n",
    "pickle.dump(MLP_clf, open('API/models/MLP_clf.pickle', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R define dimensions of empty data frame \n",
      "\n",
      "try collect data subset data set need create data frame collect result problem know create data frame define number column without actually data put c would like create df w column id max min collectid s subsetdf dfid collectmax maxssvalue collectmin minssvalue feel ask question almost feel like ask find would greatly appreciate help \n",
      "\n",
      "r define dimension empty data frame try collect data subset data set need create data frame collect result problem know create data frame define number column without actually data put c would like create df w column id max min collectid s subsetdf dfid collectmax maxssvalue collectmin minssvalue feel ask question almost feel like ask find would greatly appreciate help\n",
      "\n",
      " Tags prediction :  \n",
      "\n",
      "r 1\n",
      "\n",
      " Tags labels :  \n",
      "\n",
      "r 1\n",
      "F1 score : \n"
     ]
    },
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_sample = 1002\n",
    "new_post = text_train[id_sample]\n",
    "text_preciction_labels(new_post,vect_X,vect_Y,MLP_clf,df_questions)\n",
    "\n",
    "y_train_MLP_pred = MLP_clf.predict(X_train)\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F1 score : ')\n",
    "y_train_MLP_pred_ones = (y_train_MLP_pred >0).astype(int)\n",
    "f1_score(Y_train, y_train_MLP_pred_ones, average='weighted')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### pour 20 000 post\n",
    "Cross validation CV=5\n",
    "MLPClassifier(max_iter=500), param_grid, cv=5, scoring='f1_micro')\n",
    "\n",
    "Best cross-validation score: 0.87\n",
    "Best parameters:  {'learning_rate_init': 0.001, 'alpha': 0.1}\n",
    "Best nombre de features:  2\n",
    "['python', 'r']\n",
    "\n",
    "Best cross-validation score: 0.88\n",
    "Best parameters:  {'learning_rate_init': 0.0001, 'alpha': 0.1}\n",
    "Best nombre de features:  4\n",
    "['django', 'ggplot2', 'python', 'r']\n",
    "\n",
    "Best cross-validation score: 0.92\n",
    "Best parameters:  {'learning_rate_init': 0.0001, 'alpha': 0.1}\n",
    "Best nombre de features:  8\n",
    "['dataframe', 'django', 'ggplot2', 'list', 'numpy', 'python', 'r', 'string']\n",
    "\n",
    "Best cross-validation score: 0.87\n",
    "Best parameters:  {'learning_rate_init': 0.0001, 'alpha': 0.1}\n",
    "Best nombre de features:  16\n",
    "['2', '3', 'data', 'dataframe', 'dictionary', 'django', 'ggplot2', 'list', 'matplotlib', 'numpy', 'pandas', 'python', 'r', 'regex', 'string', 'x']\n",
    "\n",
    "Best cross-validation score: 0.91\n",
    "Best parameters:  {'learning_rate_init': 0.0001, 'alpha': 0.1}\n",
    "Best nombre de features:  32\n",
    "['2', '3', '7', 'class', 'data', 'dataframe', 'datetime', 'dictionary', 'django', 'dplyr', 'faq', 'file', 'flask', 'function', 'ggplot2', 'import', 'list', 'matplotlib', 'models', 'numpy', 'pandas', 'performance', 'plot', 'python', 'r', 'regex', 'scipy', 'sqlalchemy', 'string', 'table', 'testing', 'x']\n",
    "\n",
    "CPU times: user 13d 12h 11min 43s, sys: 2h 41min 2s, total: 13d 14h 52min 45s\n",
    "Wall time: 2d 7h 36min 50s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "clf=grid.best_estimator_\n",
    "\n",
    "pickle.dump(clf, open('models/final_prediction.pickle', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_sample = 100\n",
    "new_post = text_train[id_sample]\n",
    "new_post_vect = vect_X.transform([new_post])\n",
    "y_predict = clf.predict(new_post_vect)\n",
    "\n",
    "tags = np.argsort(y_predict[0,:])[::-1][:10].tolist()\n",
    "scores = np.sort(y_predict[0,:])[::-1][:10]\n",
    "print(df_questions.Title_raw[id_sample],'\\n')\n",
    "print(df_questions.Body[id_sample],'\\n')\n",
    "print(text_train[id_sample])\n",
    "for tag,score in zip(tags,scores) :\n",
    "    if score > 0  :\n",
    "        print(feature_names_Y[tag],score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_labels = Y_train[id_sample]\n",
    "tags = np.argsort(y_labels)[::-1][:10].tolist()\n",
    "scores = np.sort(y_labels)[::-1][:10]\n",
    "for tag,score in zip(tags,scores) :\n",
    "    if score > 0  :\n",
    "        print(feature_names_Y[tag],score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}