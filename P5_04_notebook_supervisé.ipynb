{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc3bee7",
   "metadata": {},
   "source": [
    "Dans ce notebook nous allons analyser la base de donées des post Python et R pour un\n",
    "entrainement de modèles supervisés.\n",
    "\n",
    "Nous allons commencer avec un modèle KNN, puis RandomForest et un Multi Layer Perceptron\n",
    "pour une classification entre les posts Python et R, nous allons utiliser plusieurs tags par post\n",
    "avec la strategie One vs All\n",
    "\n",
    "Une fois le modèle entrainé nous allons comparer leurs scores F1 et choisir le meilleur pour\n",
    "l'utiliser dans notre API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce7668",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdfef178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:02:07.307946Z",
     "start_time": "2021-06-17T08:02:07.305725Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.display import display\n",
    "import pickle # pour exporter les modèles entrainés\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2dbaef",
   "metadata": {},
   "source": [
    "# Importation des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b8e2d2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:02:09.317083Z",
     "start_time": "2021-06-17T08:02:09.248501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title_raw</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3604587</td>\n",
       "      <td>use string format show zero precision</td>\n",
       "      <td>try represent number lead trail width include point example want represent seem string format let one output get illustrating problem f f line exactly would expect line ignores fact want lead zero idea thanks</td>\n",
       "      <td>python string-formatting</td>\n",
       "      <td>35</td>\n",
       "      <td>How do I use string formatting to show BOTH leading zeros and precision of 3?</td>\n",
       "      <td>use string format show zero precision try represent number lead trail width include point example want represent seem string format let one output get illustrating problem f f line exactly would expect line ignores fact want lead zero idea thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1089662</td>\n",
       "      <td>python inflate deflate implementation</td>\n",
       "      <td>interfacing server require data send deflate algorithm huffman encode lz also send data need inflate know python include c library zlib support call inflate deflate apparently provide zlib module provide compress decompress make call follow resultdata zlibdecompress basedecodedcompressedstring follow error error decompress data header check gzip make resultdata gzipgzipfile fileobj basedecodedcompressedstring error ioerror gzipped file make sense data deflate file gzipped file know implementation pyflate know implementation seem option find exist implementation ideal inflate deflate python python extension zlib c include deflate call something else execute command line ruby script since inflatedeflate call zlib fully wrap ruby seek solution lack solution insight opinion idea information result deflate encode string purpose need result follow snippet c code parameter array bytes correspond data compress string deflateandencodebasebyte data null data datalength return string compressedbase memory stream wrap stream use memorystream m memorystream use deflatestream deflatestream compressionmodecompress byte buffer memorystream deflatestreamwritedata datalength memory stream base string byte compressedbytes bytemslength seekoriginbegin msreadcompressedbytes intmslength compressedbase converttobasestringcompressedbytes return run code string encode give result deflate encode run python base encode result ejxlsulssxjvujmsfizuvotlvyefafxhbk zlibcompress implementation algorithm deflate algorithm information first bytes deflate data bhy b decode correspond gzip data xfb bzip xa data zlib xc data first bytes python compress data ejxls b decode xc zlib header solve deflate inflate without checksum follow thing need deflatecompress strip first two byte four byte checksum argument window size value suppress header method currently include base encodingdecoding work properly import zlib import base def decodebaseandinflate bstring decodeddata basebdecode bstring return zlibdecompress decodeddata def deflateandbaseencode stringval zlibbedstr zlibcompress stringval compressedstring return basebencode compressedstring</td>\n",
       "      <td>c# python compression zlib</td>\n",
       "      <td>61</td>\n",
       "      <td>Python: Inflate and Deflate implementations</td>\n",
       "      <td>python inflate deflate implementation interfacing server require data send deflate algorithm huffman encode lz also send data need inflate know python include c library zlib support call inflate deflate apparently provide zlib module provide compress decompress make call follow resultdata zlibdecompress basedecodedcompressedstring follow error error decompress data header check gzip make resultdata gzipgzipfile fileobj basedecodedcompressedstring error ioerror gzipped file make sense data deflate file gzipped file know implementation pyflate know implementation seem option find exist implementation ideal inflate deflate python python extension zlib c include deflate call something else execute command line ruby script since inflatedeflate call zlib fully wrap ruby seek solution lack solution insight opinion idea information result deflate encode string purpose need result follow snippet c code parameter array bytes correspond data compress string deflateandencodebasebyte data null data datalength return string compressedbase memory stream wrap stream use memorystream m memorystream use deflatestream deflatestream compressionmodecompress byte buffer memorystream deflatestreamwritedata datalength memory stream base string byte compressedbytes bytemslength seekoriginbegin msreadcompressedbytes intmslength compressedbase converttobasestringcompressedbytes return run code string encode give result deflate encode run python base encode result ejxlsulssxjvujmsfizuvotlvyefafxhbk zlibcompress implementation algorithm deflate algorithm information first bytes deflate data bhy b decode correspond gzip data xfb bzip xa data zlib xc data first bytes python compress data ejxls b decode xc zlib header solve deflate inflate without checksum follow thing need deflatecompress strip first two byte four byte checksum argument window size value suppress header method currently include base encodingdecoding work properly import zlib import base def decodebaseandinflate bstring decodeddata basebdecode bstring return zlibdecompress decodeddata def deflateandbaseencode stringval zlibbedstr zlibcompress stringval compressedstring return basebencode compressedstring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1185634</td>\n",
       "      <td>solve mastermind guessing game</td>\n",
       "      <td>would create solve follow puzzle mastermind choose four colour set six blue orange purple must guess choose order guess opponent tell colour guess right colour place black right colour place white game end guess correctly black white example opponent choose orange guess yellow get one two white would get score guess orange purple algorithm would choose optionally code preferably python coded solution easily concise fast make number guess solve puzzle easily answer question algorithm case easily adapt type puzzle mastermind algorithm efficient provide poorly implement however algorithm implement inflexibly impenetrably use solution python post mean approach please post expect essay</td>\n",
       "      <td>python algorithm</td>\n",
       "      <td>38</td>\n",
       "      <td>How to solve the \"Mastermind\" guessing game?</td>\n",
       "      <td>solve mastermind guessing game would create solve follow puzzle mastermind choose four colour set six blue orange purple must guess choose order guess opponent tell colour guess right colour place black right colour place white game end guess correctly black white example opponent choose orange guess yellow get one two white would get score guess orange purple algorithm would choose optionally code preferably python coded solution easily concise fast make number guess solve puzzle easily answer question algorithm case easily adapt type puzzle mastermind algorithm efficient provide poorly implement however algorithm implement inflexibly impenetrably use solution python post mean approach please post expect essay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15259547</td>\n",
       "      <td>sum pandas aggregate</td>\n",
       "      <td>recently make switch r python trouble get use data frame oppose use r problem would like take list string check value sum count string break user would like take data aid b c leave return aidgrouped overup r code use dt listaidgrouped sumdown overup sumup bylista however attempt python fail c npsumdtdtbup dtc thank advance seem like question however could find</td>\n",
       "      <td>python r pandas data.table</td>\n",
       "      <td>22</td>\n",
       "      <td>conditional sums for pandas aggregate</td>\n",
       "      <td>sum pandas aggregate recently make switch r python trouble get use data frame oppose use r problem would like take list string check value sum count string break user would like take data aid b c leave return aidgrouped overup r code use dt listaidgrouped sumdown overup sumup bylista however attempt python fail c npsumdtdtbup dtc thank advance seem like question however could find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2317849</td>\n",
       "      <td>use sock proxy urllib</td>\n",
       "      <td>use sock proxy download web page</td>\n",
       "      <td>python proxy urllib2 socks</td>\n",
       "      <td>48</td>\n",
       "      <td>How can I use a SOCKS 4/5 proxy with urllib2?</td>\n",
       "      <td>use sock proxy urllib use sock proxy download web page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                  Title  \\\n",
       "0   3604587  use string format show zero precision   \n",
       "1   1089662  python inflate deflate implementation   \n",
       "2   1185634         solve mastermind guessing game   \n",
       "3  15259547                   sum pandas aggregate   \n",
       "4   2317849                  use sock proxy urllib   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Body  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             try represent number lead trail width include point example want represent seem string format let one output get illustrating problem f f line exactly would expect line ignores fact want lead zero idea thanks   \n",
       "1  interfacing server require data send deflate algorithm huffman encode lz also send data need inflate know python include c library zlib support call inflate deflate apparently provide zlib module provide compress decompress make call follow resultdata zlibdecompress basedecodedcompressedstring follow error error decompress data header check gzip make resultdata gzipgzipfile fileobj basedecodedcompressedstring error ioerror gzipped file make sense data deflate file gzipped file know implementation pyflate know implementation seem option find exist implementation ideal inflate deflate python python extension zlib c include deflate call something else execute command line ruby script since inflatedeflate call zlib fully wrap ruby seek solution lack solution insight opinion idea information result deflate encode string purpose need result follow snippet c code parameter array bytes correspond data compress string deflateandencodebasebyte data null data datalength return string compressedbase memory stream wrap stream use memorystream m memorystream use deflatestream deflatestream compressionmodecompress byte buffer memorystream deflatestreamwritedata datalength memory stream base string byte compressedbytes bytemslength seekoriginbegin msreadcompressedbytes intmslength compressedbase converttobasestringcompressedbytes return run code string encode give result deflate encode run python base encode result ejxlsulssxjvujmsfizuvotlvyefafxhbk zlibcompress implementation algorithm deflate algorithm information first bytes deflate data bhy b decode correspond gzip data xfb bzip xa data zlib xc data first bytes python compress data ejxls b decode xc zlib header solve deflate inflate without checksum follow thing need deflatecompress strip first two byte four byte checksum argument window size value suppress header method currently include base encodingdecoding work properly import zlib import base def decodebaseandinflate bstring decodeddata basebdecode bstring return zlibdecompress decodeddata def deflateandbaseencode stringval zlibbedstr zlibcompress stringval compressedstring return basebencode compressedstring   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            would create solve follow puzzle mastermind choose four colour set six blue orange purple must guess choose order guess opponent tell colour guess right colour place black right colour place white game end guess correctly black white example opponent choose orange guess yellow get one two white would get score guess orange purple algorithm would choose optionally code preferably python coded solution easily concise fast make number guess solve puzzle easily answer question algorithm case easily adapt type puzzle mastermind algorithm efficient provide poorly implement however algorithm implement inflexibly impenetrably use solution python post mean approach please post expect essay   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   recently make switch r python trouble get use data frame oppose use r problem would like take list string check value sum count string break user would like take data aid b c leave return aidgrouped overup r code use dt listaidgrouped sumdown overup sumup bylista however attempt python fail c npsumdtdtbup dtc thank advance seem like question however could find   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             use sock proxy download web page   \n",
       "\n",
       "                         Tags  Score  \\\n",
       "0    python string-formatting     35   \n",
       "1  c# python compression zlib     61   \n",
       "2            python algorithm     38   \n",
       "3  python r pandas data.table     22   \n",
       "4  python proxy urllib2 socks     48   \n",
       "\n",
       "                                                                       Title_raw  \\\n",
       "0  How do I use string formatting to show BOTH leading zeros and precision of 3?   \n",
       "1                                    Python: Inflate and Deflate implementations   \n",
       "2                                   How to solve the \"Mastermind\" guessing game?   \n",
       "3                                          conditional sums for pandas aggregate   \n",
       "4                                  How can I use a SOCKS 4/5 proxy with urllib2?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Text  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             use string format show zero precision try represent number lead trail width include point example want represent seem string format let one output get illustrating problem f f line exactly would expect line ignores fact want lead zero idea thanks  \n",
       "1  python inflate deflate implementation interfacing server require data send deflate algorithm huffman encode lz also send data need inflate know python include c library zlib support call inflate deflate apparently provide zlib module provide compress decompress make call follow resultdata zlibdecompress basedecodedcompressedstring follow error error decompress data header check gzip make resultdata gzipgzipfile fileobj basedecodedcompressedstring error ioerror gzipped file make sense data deflate file gzipped file know implementation pyflate know implementation seem option find exist implementation ideal inflate deflate python python extension zlib c include deflate call something else execute command line ruby script since inflatedeflate call zlib fully wrap ruby seek solution lack solution insight opinion idea information result deflate encode string purpose need result follow snippet c code parameter array bytes correspond data compress string deflateandencodebasebyte data null data datalength return string compressedbase memory stream wrap stream use memorystream m memorystream use deflatestream deflatestream compressionmodecompress byte buffer memorystream deflatestreamwritedata datalength memory stream base string byte compressedbytes bytemslength seekoriginbegin msreadcompressedbytes intmslength compressedbase converttobasestringcompressedbytes return run code string encode give result deflate encode run python base encode result ejxlsulssxjvujmsfizuvotlvyefafxhbk zlibcompress implementation algorithm deflate algorithm information first bytes deflate data bhy b decode correspond gzip data xfb bzip xa data zlib xc data first bytes python compress data ejxls b decode xc zlib header solve deflate inflate without checksum follow thing need deflatecompress strip first two byte four byte checksum argument window size value suppress header method currently include base encodingdecoding work properly import zlib import base def decodebaseandinflate bstring decodeddata basebdecode bstring return zlibdecompress decodeddata def deflateandbaseencode stringval zlibbedstr zlibcompress stringval compressedstring return basebencode compressedstring  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   solve mastermind guessing game would create solve follow puzzle mastermind choose four colour set six blue orange purple must guess choose order guess opponent tell colour guess right colour place black right colour place white game end guess correctly black white example opponent choose orange guess yellow get one two white would get score guess orange purple algorithm would choose optionally code preferably python coded solution easily concise fast make number guess solve puzzle easily answer question algorithm case easily adapt type puzzle mastermind algorithm efficient provide poorly implement however algorithm implement inflexibly impenetrably use solution python post mean approach please post expect essay  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    sum pandas aggregate recently make switch r python trouble get use data frame oppose use r problem would like take list string check value sum count string break user would like take data aid b c leave return aidgrouped overup r code use dt listaidgrouped sumdown overup sumup bylista however attempt python fail c npsumdtdtbup dtc thank advance seem like question however could find  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             use sock proxy urllib use sock proxy download web page  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtypes_questions = {'Id':'int32', 'Score': 'int16', 'Title': 'str',\n",
    "                    'Body': 'str', 'Title_raw': 'str', 'Text': 'str',\n",
    "                    'Tags': 'str'}\n",
    "\n",
    "nrows = 4000\n",
    "\n",
    "df_questions = pd.read_csv('df_questions_fullclean.csv',\n",
    "                           usecols=dtypes_questions.keys(),\n",
    "                           encoding = \"utf-8\",\n",
    "                           dtype=dtypes_questions,\n",
    "                           nrows=nrows\n",
    "                          )\n",
    "\n",
    "print(len(df_questions))\n",
    "display(df_questions.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47355cd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:02:10.096443Z",
     "start_time": "2021-06-17T08:02:10.092028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of text_train: <class 'pandas.core.series.Series'>\n",
      "length of text_train: 4000\n",
      "text_train[6]:\n",
      "match fuzzy match string two datasets work way join two datasets base string name company match two dirty list one list name information another list names address neither ids match assume clean already apply maybe insertion far agrep tool find might work use distance package measure number deletion insertion substitution two string agrep return string distance however trouble turn command value apply data frame crudely use repeat function get way see follow code cobayes asd baes bayspricec bdataframenamecace cobayes incasdfqtyc agrepanamei bname value max listdel ins ayi agrepanamei bname value max listdel in\n"
     ]
    }
   ],
   "source": [
    "# création des labels python et r\n",
    "text, tag = df_questions.Text, df_questions.Tags\n",
    "print(\"type of text_train: {}\".format(type(text)))\n",
    "print(\"length of text_train: {}\".format(len(text)))\n",
    "print(\"text_train[6]:\\n{}\".format(text[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7821be9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:02:10.852003Z",
     "start_time": "2021-06-17T08:02:10.849417Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "107f0c04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:02:11.491251Z",
     "start_time": "2021-06-17T08:02:11.484035Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3df73fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:02:11.991785Z",
     "start_time": "2021-06-17T08:02:11.987486Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ajouter les fichiers pour test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9eb760",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Répresenter les données textuelles comme un bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e8b1191",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:07:02.110901Z",
     "start_time": "2021-06-17T09:07:01.800428Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<2000x25593 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 66639 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect_X = CountVectorizer().fit(text)\n",
    "X = vect_X.transform(text)\n",
    "\n",
    "# Les posts ont été randomisés dans le prétraitement, nous utilisons les premiers 1000 post\n",
    "# comme Validation et les suivants 1000 comme notre test set le restant de notre dataset\n",
    "# sera utilisé pour entrainement du modèle\n",
    "\n",
    "X_val = X[:1000]\n",
    "X_test = X[1000:2000]\n",
    "X_train = X[2000:]\n",
    "\n",
    "pickle.dump(vect_X, open('API/models/vect_X.pickle', 'wb')) # enregistre le modeèle de transformation X\n",
    "\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "56034ecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:07:02.350888Z",
     "start_time": "2021-06-17T09:07:02.320459Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 25593\n",
      "First 20 features:\n",
      "['aa', 'aaa', 'aaaaa', 'aaaaaaaaaa', 'aaab', 'aaabbb', 'aaabbzzyy', 'aaardvark', 'aab', 'aababcbac', 'aabbcdefg', 'aabbzzyy', 'aabcd', 'aac', 'aadata', 'aaf', 'aafaf', 'aall', 'aamir', 'aandalucia']\n",
      "Features 20010 to 20030:\n",
      "['selfinitb', 'selfinitdefaultregister', 'selfinitialjobrecord', 'selfinitialoperators', 'selfinitmessage', 'selfinitsocketafinet', 'selfinittupleb', 'selfinstreamread', 'selfintersecting', 'selfinventorynames', 'selfitem', 'selfjointloglikelihoodx', 'selfkey', 'selfkids', 'selfkillreceived', 'selfknowledge', 'selfl', 'selflabelencodertransformselftrainlabels', 'selflabeltext', 'selflearnc']\n",
      "Every 2000th feature:\n",
      "['aa', 'boolean', 'cperform', 'docallload', 'frameroot', 'icudata', 'light', 'mydir', 'patchgetpatchtransformtransformvertices', 'read', 'selfidxnil', 'summarisenew', 'vba']\n"
     ]
    }
   ],
   "source": [
    "feature_names_X = vect_X.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names_X)))\n",
    "print(\"First 20 features:\\n{}\".format(feature_names_X[:20]))\n",
    "print(\"Features 20010 to 20030:\\n{}\".format(feature_names_X[20010:20030]))\n",
    "print(\"Every 2000th feature:\\n{}\".format(feature_names_X[::2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "583a9926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:07:03.083897Z",
     "start_time": "2021-06-17T09:07:03.037908Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train:\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "vect_Y = CountVectorizer(binary=True,\n",
    "                         max_features=None,\n",
    "                         token_pattern=rx).fit(tag)\n",
    "# nous avons laissé l'option binary true car il est inutile d'avoir plus d'une fois le même token\n",
    "# nous allons limiter le nombre de de features car le F1 Score avec tous les tags pour le modèle KNN est 0.013\n",
    "# avec 10 features nous arrivons à un F1 Score de 37,8%\n",
    "# On utilise un token_pattern different pour pouvoir récupérer le tag r\n",
    "Y = vect_Y.transform(tag).toarray()\n",
    "\n",
    "Y_val = Y[:1000]\n",
    "Y_test = Y[1000:2000]\n",
    "Y_train = Y[2000:]\n",
    "\n",
    "pickle.dump(vect_Y, open('API/models/vect_Y.pickle',\n",
    "                         'wb'))  # enregistre le modèle de transformation Y\n",
    "\n",
    "print(\"Y_train:\\n{}\".format(repr(Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "20e6d5e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:07:03.650633Z",
     "start_time": "2021-06-17T09:07:03.639663Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1802\n",
      "First 20 features:\n",
      "['32bit-64bit', '3d', '64-bit', 'a-star', 'aabb', 'abc', 'abort', 'absolute-path', 'abstract', 'abstract-class', 'abstract-syntax-tree', 'accessor', 'action', 'active-directory', 'aesthetics', 'aggregate', 'aggregate-functions', 'algorithm', 'alias', 'alignment']\n",
      "Features 210 to 230:\n",
      "['lattice', 'layout', 'lazy-evaluation', 'lazy-loading', 'lda', 'ldap', 'leaflet', 'left-join', 'legend', 'legend-properties', 'lemmatization', 'let', 'levels', 'libcurl', 'libraries', 'libsvm', 'libvlc', 'licensing', 'limit', 'line']\n",
      "Every 200th feature:\n",
      "['32bit-64bit', 'collation', 'django-urls', 'github-pages', 'lattice', 'nose', 'pyparsing', 'search', 'text', 'zoo']\n"
     ]
    }
   ],
   "source": [
    "feature_names_Y = vect_Y.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names_Y)))\n",
    "print(\"First 20 features:\\n{}\".format(feature_names_Y[:20]))\n",
    "print(\"Features 210 to 230:\\n{}\".format(feature_names_Y[800:820]))\n",
    "print(\"Every 200th feature:\\n{}\".format(feature_names_Y[::200]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf2e7a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Modèle KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14960ed",
   "metadata": {},
   "source": [
    "## Définition de fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d269a409",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:07:04.810215Z",
     "start_time": "2021-06-17T09:07:04.805068Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def text_prediction_labels(new_post, vect_X, vect_Y, model, df_questions):\n",
    "    '''\n",
    "        Cette fonction fait une prediction de tags avec le \"model\"\n",
    "        il transforme le texte en vecteur avec vect_X\n",
    "        il fait la prédiction qu'il transforme avec vect_Y\n",
    "        il affiche la prédiction ainsi que le score donnée par le modèle\n",
    "        il affiche aussi les vrais labels\n",
    "    '''\n",
    "    feature_names_Y = vect_Y.get_feature_names() # liste des tags\n",
    "    Y_train = vect_Y.transform(df_questions.Tags) # liste des listes des Tags par post\n",
    "    new_post_vect = vect_X.transform([new_post]) # vectorisation du nouveau post pour prediction du modèle\n",
    "    y_predict = model.predict(new_post_vect) # prediction du modèle entrainé\n",
    "\n",
    "    tags = np.argsort(y_predict[0,:])[::-1][:10].tolist()\n",
    "    scores = np.sort(y_predict[0,:])[::-1][:10]\n",
    "\n",
    "    print(df_questions.Title_raw[id_sample],'\\n')\n",
    "    print(df_questions.Body[id_sample],'\\n')\n",
    "    print(df_questions.Text[id_sample])\n",
    "    print('\\n','Tags prediction : ', '\\n')\n",
    "    for tag,score in zip(tags,scores) :\n",
    "        if score > 0  :\n",
    "            print(feature_names_Y[tag],score)\n",
    "    print('\\n','Tags labels : ','\\n')\n",
    "    \n",
    "    y_labels = Y_train[id_sample].toarray()\n",
    "    tags = np.argsort(y_labels[0,:])[::-1][:10].tolist()\n",
    "    scores = np.sort(y_labels[0,:])[::-1][:10]\n",
    "    for tag,score in zip(tags,scores) :\n",
    "        if score > 0  :\n",
    "            print(feature_names_Y[tag],score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d49fe91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:51:41.375758Z",
     "start_time": "2021-06-17T08:51:41.369769Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score , precision_score, recall_score\n",
    "\n",
    "def model_score(model,X_vect,tag_text,vect_Y,names=False,seuil=0.5):\n",
    "    '''\n",
    "        cette fonction affiche les résultats f1, precision et recall pour le modele choisi\n",
    "        une option de seuil est ajouté pour modifier le trade-off precision/recall\n",
    "        nous pouvons aussi afficher ou pas les tags\n",
    "    '''\n",
    "    Y = vect_Y.transform(tag_text).toarray()\n",
    "\n",
    "    y_model_pred = model.predict(X_vect)\n",
    "    y_model_pred_ones = (y_model_pred >seuil).astype(int)\n",
    "    \n",
    "    f1_score_model        = f1_score(Y, y_model_pred_ones, average=\"micro\")\n",
    "    precision_score_model = precision_score(Y, y_model_pred_ones, average=\"micro\")\n",
    "    recall_score_model    = recall_score(Y, y_model_pred_ones, average=\"micro\")\n",
    "    \n",
    "    nb_tag = len(Y[0])\n",
    "    \n",
    "    print(\"Nombre de Tags pour l'entrainement: \", nb_tag)\n",
    "    if names :\n",
    "        print(vect_Y.get_feature_names(),'\\n')\n",
    "    print(\"f1-score: {:.2f}\".format(f1_score_model))\n",
    "    print(\"precision_score: {:.2f}\".format(precision_score_model))\n",
    "    print(\"recall_score: {:.2f}\".format(recall_score_model))\n",
    "    print(\"Model parameters: \", model.get_params,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d130009",
   "metadata": {},
   "source": [
    "## Entrainement du modèle avec tous les labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "699f4629",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:07:05.654819Z",
     "start_time": "2021-06-17T09:07:05.439543Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(weights ='distance') # le plus proche voisin est privilegié \n",
    "knn_clf.fit(X_train, Y_train)\n",
    "\n",
    "pickle.dump(knn_clf, open('API/models/knn_clf.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aafccdcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:19:33.212802Z",
     "start_time": "2021-06-17T09:19:33.103368Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to do multiple imports in Python? \n",
      "\n",
      "ruby instead repeat require import python word lot time lib lib libeach x require x iterate set libs require import one writing python script would like something like way need import straightforward traduction would something like follow code anyway since python import libs name string work requirement lib lib lib lib requirement import thanks advance \n",
      "\n",
      "import python ruby instead repeat require import python word lot time lib lib libeach x require x iterate set libs require import one writing python script would like something like way need import straightforward traduction would something like follow code anyway since python import libs name string work requirement lib lib lib lib requirement import thanks advance\n",
      "\n",
      " Tags prediction :  \n",
      "\n",
      "python 1\n",
      "\n",
      " Tags labels :  \n",
      "\n",
      "require 1\n",
      "python 1\n",
      "iterator 1\n",
      "import 1\n"
     ]
    }
   ],
   "source": [
    "# exemple de prédiction val set entre 0 et 1000 test set entre 1000 \n",
    "# et 2000 et train set au délà de 2000\n",
    "\n",
    "id_sample = 1500\n",
    "new_post = text[id_sample]\n",
    "text_prediction_labels(new_post,vect_X,vect_Y,knn_clf,df_questions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30294516",
   "metadata": {},
   "source": [
    "### Visualisation des prédiction vs les labels pour le trains set et test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c642812a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:03:34.782890Z",
     "start_time": "2021-06-17T08:03:34.076257Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred =knn_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40a4a00f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:03:35.402097Z",
     "start_time": "2021-06-17T08:03:35.385396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  14,   14,   15,   15,   15,   15,   15,   17,   17,   18,   18,\n",
       "         18,   19,   19,   19,   20,   21,   22,   24,   24,   26,   27,\n",
       "         27,   28,   28,   30,   31,   31,   37,   39,   42,   55,   55,\n",
       "         60,   72,   84,   92,  104,  575, 1434])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_one = (y_pred>0.5).astype(int)\n",
    "np.sort(np.sum(y_pred_one,axis=0))[-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef44173a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:05:15.962834Z",
     "start_time": "2021-06-17T08:05:15.957697Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  14,   14,   15,   15,   15,   15,   15,   17,   17,   18,   18,\n",
       "         18,   19,   19,   19,   20,   21,   22,   24,   24,   26,   27,\n",
       "         27,   28,   28,   30,   31,   31,   37,   39,   42,   55,   55,\n",
       "         60,   72,   84,   92,  104,  575, 1434])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.sum(Y_train,axis=0))[-40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1da2bd1",
   "metadata": {},
   "source": [
    "Les predictions sont les mêmes que les labels car nos avons choisi de privilegier la distance dans notre modèle, les predictions correspondent au plus proche voisin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "819b2752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:06:28.652791Z",
     "start_time": "2021-06-17T08:06:28.307792Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred =knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f597d5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:07:11.799309Z",
     "start_time": "2021-06-17T08:07:11.791782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   2,   2,\n",
       "         2,   2,   3,   3,   3,   5,   6,   6,  10,  11,  22,  33,  90,\n",
       "       919])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_one = (y_test_pred>0.5).astype(int)\n",
    "np.sort(np.sum(y_test_pred_one,axis=0))[-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af83e2d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:07:31.520822Z",
     "start_time": "2021-06-17T08:07:31.509915Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8,   8,   8,   9,   9,   9,   9,  10,  10,  10,  10,  10,  10,\n",
       "        11,  11,  11,  12,  12,  12,  12,  13,  14,  15,  16,  16,  17,\n",
       "        17,  18,  19,  25,  25,  26,  29,  33,  33,  45,  46,  62, 282,\n",
       "       727])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.sum(Y_test,axis=0))[-40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14160d84",
   "metadata": {},
   "source": [
    "Sur le test set nous avons beaucoup moins de tags dans les predictions que dans les labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4598998",
   "metadata": {},
   "source": [
    "## Metrics : f1 score, precision et recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ee2777",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35ba4035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:45:29.350328Z",
     "start_time": "2021-06-17T08:45:28.238309Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.11 s, sys: 0 ns, total: 1.11 s\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 50 secondes pour calculer 2000 lignes\n",
    "# 15min 57s pour 20 000 lignes\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, Y_train, cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b8a264d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:47:15.526398Z",
     "start_time": "2021-06-17T08:47:14.762477Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "résultats suite à une cross validation sur le train set\n",
      "f1 :  0.4118083003952569\n",
      "precision :  0.7465293327362292\n",
      "recall :  0.2843254306668941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,precision_score, recall_score\n",
    "\n",
    "y_train_knn_pred_ones = (y_train_knn_pred >0.5).astype(int)\n",
    "print('résultats suite à une cross validation sur le train set')\n",
    "print('f1 : ',f1_score(Y_train, y_train_knn_pred_ones, average=\"micro\"))\n",
    "print('precision : ',precision_score(Y_train, y_train_knn_pred_ones, average=\"micro\"))\n",
    "print('recall : ',recall_score(Y_train, y_train_knn_pred_ones, average=\"micro\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead14b9",
   "metadata": {},
   "source": [
    "### sur Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c25ec0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:52:22.147910Z",
     "start_time": "2021-06-17T08:52:21.424719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de Tags pour l'entrainement:  1802\n",
      "f1-score: 0.42\n",
      "precision_score: 0.75\n",
      "recall_score: 0.29\n",
      "Model parameters:  <bound method BaseEstimator.get_params of KNeighborsClassifier(weights='distance')> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_score(knn_clf,X_test,tag[1000:2000],vect_Y,seuil=0.2) \n",
    "# le seuil n'a pas d'infuence dans le modèlde KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb498cc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:53:58.575439Z",
     "start_time": "2021-06-17T08:53:57.146270Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de Tags pour l'entrainement:  1802\n",
      "f1-score: 1.00\n",
      "precision_score: 1.00\n",
      "recall_score: 1.00\n",
      "Model parameters:  <bound method BaseEstimator.get_params of KNeighborsClassifier(weights='distance')> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_score(knn_clf,X_train,tag[2000:],vect_Y,seuil=0.2) \n",
    "# le modèle a overfitté le train set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae243aa",
   "metadata": {},
   "source": [
    "Comme vu plus ahut nous avons des scores parfait sur le train_set, mais des résultats beaucoup moins encourageants avec le test set, nous allons tenter de augmenter la précision en diminuant le nombre de tags possibles. ceci devrait diminuer le nombre de faux positifs, donc la précision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eb6493",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Création d'une pipeline pour choisir le meilleurs parametre pour ce modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52b137c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:37:44.670466Z",
     "start_time": "2021-06-17T09:37:24.185742Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de features:  2\n",
      "['python', 'r']\n",
      "Best cross-validation f1-score: 0.76\n",
      "Best parameters:  {'n_neighbors': 6} \n",
      "\n",
      "Nombre de features:  4\n",
      "['django', 'ggplot2', 'python', 'r']\n",
      "Best cross-validation f1-score: 0.73\n",
      "Best parameters:  {'n_neighbors': 6} \n",
      "\n",
      "Nombre de features:  6\n",
      "['django', 'ggplot2', 'list', 'numpy', 'python', 'r']\n",
      "Best cross-validation f1-score: 0.71\n",
      "Best parameters:  {'n_neighbors': 6} \n",
      "\n",
      "Nombre de features:  8\n",
      "['dataframe', 'django', 'ggplot2', 'list', 'numpy', 'python', 'r', 'string']\n",
      "Best cross-validation f1-score: 0.69\n",
      "Best parameters:  {'n_neighbors': 6} \n",
      "\n",
      "Nombre de features:  16\n",
      "['data.table', 'dataframe', 'datetime', 'dictionary', 'django', 'ggplot2', 'list', 'matplotlib', 'numpy', 'pandas', 'plot', 'python', 'python-3.x', 'r', 'regex', 'string']\n",
      "Best cross-validation f1-score: 0.65\n",
      "Best parameters:  {'n_neighbors': 6} \n",
      "\n",
      "Nombre de features:  32\n",
      "['arrays', 'class', 'data.table', 'dataframe', 'datetime', 'dictionary', 'django', 'dplyr', 'file', 'flask', 'function', 'ggplot2', 'knitr', 'linux', 'list', 'matplotlib', 'numpy', 'pandas', 'performance', 'plot', 'python', 'python-2.7', 'python-3.x', 'r', 'r-faq', 'regex', 'scipy', 'sqlalchemy', 'string', 'unicode', 'unit-testing', 'windows']\n",
      "Best cross-validation f1-score: 0.61\n",
      "Best parameters:  {'n_neighbors': 6} \n",
      "\n",
      "CPU times: user 20.5 s, sys: 39.9 ms, total: 20.5 s\n",
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 6min 42s pour 20 000 post\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_neighbors' : [2,4,6, 8,32,]}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='f1_micro')\n",
    "\n",
    "best_score = 0\n",
    "best_param = {}\n",
    "best_feature_number = 0\n",
    "\n",
    "for i in [2,4,6,8,16,32]: # testet avec un nombre limité de tags\n",
    "    vect_Y = CountVectorizer(binary=True, token_pattern= rx, max_features=i).fit(tag[2000:])\n",
    "    Y_train = vect_Y.transform(tag[2000:]).toarray()\n",
    "    grid.fit(X_train, Y_train)\n",
    "    best_score = grid.best_score_\n",
    "    best_param = grid.best_params_\n",
    "    best_feature_number = i\n",
    "    print(\"Nombre de features: \", best_feature_number)\n",
    "    print(vect_Y.get_feature_names())\n",
    "    print(\"Best cross-validation f1-score: {:.2f}\".format(best_score))\n",
    "    print(\"Best parameters: \", best_param,'\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b6aa1",
   "metadata": {},
   "source": [
    "## Meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f7c9d961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:58:34.477774Z",
     "start_time": "2021-06-17T08:58:34.453267Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding Environment variable in string using python \n",
      "\n",
      "string contain environment mypath homedirdir want parse string look replace string print home osenvironhome myexpandedpath parsestringmypath print path myexpandedpath see output home homeuser path homeuserdirdir way thanks conor \n",
      "\n",
      "expand environment string use python string contain environment mypath homedirdir want parse string look replace string print home osenvironhome myexpandedpath parsestringmypath print path myexpandedpath see output home homeuser path homeuserdirdir way thanks conor\n",
      "\n",
      " Tags prediction :  \n",
      "\n",
      "string 1\n",
      "python 1\n",
      "\n",
      " Tags labels :  \n",
      "\n",
      "python 1\n"
     ]
    }
   ],
   "source": [
    "KNNmodel = grid.best_estimator_\n",
    "\n",
    "id_sample = 10\n",
    "new_post = text[id_sample]\n",
    "text_prediction_labels(new_post,vect_X,vect_Y,KNNmodel,df_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d814bd1",
   "metadata": {},
   "source": [
    "Avec 32 Tags (et 2000 post) nous avons\n",
    "\n",
    "- f1-score de 61%\n",
    "- précision de 78% # la précision n'a pas beaucoup évolué car le spost python et r sont généralement bien prédit\n",
    "- recall de 49%\n",
    "\n",
    "Avec tous les Tags soit 1802\n",
    "\n",
    "- f1-score: 42 %\n",
    "- precision_score: 75 % \n",
    "- recall_score: 29 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c2db962",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T08:58:57.765254Z",
     "start_time": "2021-06-17T08:58:56.905918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de Tags pour l'entrainement:  32\n",
      "['arrays', 'class', 'data.table', 'dataframe', 'datetime', 'dictionary', 'django', 'dplyr', 'file', 'flask', 'function', 'ggplot2', 'knitr', 'linux', 'list', 'matplotlib', 'numpy', 'pandas', 'performance', 'plot', 'python', 'python-2.7', 'python-3.x', 'r', 'r-faq', 'regex', 'scipy', 'sqlalchemy', 'string', 'unicode', 'unit-testing', 'windows'] \n",
      "\n",
      "f1-score: 0.61\n",
      "precision_score: 0.78\n",
      "recall_score: 0.49\n",
      "Model parameters:  <bound method BaseEstimator.get_params of KNeighborsClassifier(n_neighbors=6)> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_score(KNNmodel,X_test,tag[1000:2000],vect_Y,names=True,seuil=0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754c00b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "31ec4f88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:56:33.328696Z",
     "start_time": "2021-06-17T09:49:54.354839Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de features:  2\n",
      "['python', 'r']\n",
      "Best cross-validation f1-score: 0.73\n",
      "Best parameters:  {'max_depth': 8, 'n_estimators': 100} \n",
      "\n",
      "Nombre de features:  4\n",
      "['django', 'ggplot2', 'python', 'r']\n",
      "Best cross-validation f1-score: 0.69\n",
      "Best parameters:  {'max_depth': 8, 'n_estimators': 100} \n",
      "\n",
      "Nombre de features:  8\n",
      "['dataframe', 'django', 'ggplot2', 'list', 'numpy', 'python', 'r', 'string']\n",
      "Best cross-validation f1-score: 0.65\n",
      "Best parameters:  {'max_depth': 8, 'n_estimators': 100} \n",
      "\n",
      "Nombre de features:  16\n",
      "['data.table', 'dataframe', 'datetime', 'dictionary', 'django', 'ggplot2', 'list', 'matplotlib', 'numpy', 'pandas', 'plot', 'python', 'python-3.x', 'r', 'regex', 'string']\n",
      "Best cross-validation f1-score: 0.61\n",
      "Best parameters:  {'max_depth': 8, 'n_estimators': 1000} \n",
      "\n",
      "Nombre de features:  32\n",
      "['arrays', 'class', 'data.table', 'dataframe', 'datetime', 'dictionary', 'django', 'dplyr', 'file', 'flask', 'function', 'ggplot2', 'knitr', 'linux', 'list', 'matplotlib', 'numpy', 'pandas', 'performance', 'plot', 'python', 'python-2.7', 'python-3.x', 'r', 'r-faq', 'regex', 'scipy', 'sqlalchemy', 'string', 'unicode', 'unit-testing', 'windows']\n",
      "Best cross-validation f1-score: 0.57\n",
      "Best parameters:  {'max_depth': 8, 'n_estimators': 100} \n",
      "\n",
      "CPU times: user 6min 38s, sys: 722 ms, total: 6min 38s\n",
      "Wall time: 6min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 4h 32min 57s pour 20 000 posts\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {'n_estimators' : [100,500,1000],\n",
    "              'max_depth' : [2,4,8]\n",
    "              }\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='f1_micro')\n",
    "\n",
    "best_score = 0\n",
    "best_param = {}\n",
    "best_feature_number = 0\n",
    "\n",
    "for i in [2,4,8,16,32]:\n",
    "    vect_Y = CountVectorizer(binary=True, token_pattern= rx, max_features=i).fit(tag[2000:])\n",
    "    Y_train = vect_Y.transform(tag[2000:]).toarray()\n",
    "    grid.fit(X_train, Y_train)\n",
    "    best_score = grid.best_score_\n",
    "    best_param = grid.best_params_\n",
    "    best_feature_number = i\n",
    "    print(\"Nombre de features: \", best_feature_number)\n",
    "    print(vect_Y.get_feature_names())\n",
    "    print(\"Best cross-validation f1-score: {:.2f}\".format(best_score))\n",
    "    print(\"Best parameters: \", best_param,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f425b5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:56:33.429779Z",
     "start_time": "2021-06-17T09:56:33.374413Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding Environment variable in string using python \n",
      "\n",
      "string contain environment mypath homedirdir want parse string look replace string print home osenvironhome myexpandedpath parsestringmypath print path myexpandedpath see output home homeuser path homeuserdirdir way thanks conor \n",
      "\n",
      "expand environment string use python string contain environment mypath homedirdir want parse string look replace string print home osenvironhome myexpandedpath parsestringmypath print path myexpandedpath see output home homeuser path homeuserdirdir way thanks conor\n",
      "\n",
      " Tags prediction :  \n",
      "\n",
      "python 1\n",
      "\n",
      " Tags labels :  \n",
      "\n",
      "python 1\n"
     ]
    }
   ],
   "source": [
    "RandomForestmodel = grid.best_estimator_\n",
    "\n",
    "id_sample = 10\n",
    "new_post = text[id_sample]\n",
    "text_prediction_labels(new_post,vect_X,vect_Y,RandomForestmodel,df_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a030587b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:56:33.684092Z",
     "start_time": "2021-06-17T09:56:33.471033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de Tags pour l'entrainement:  32\n",
      "['arrays', 'class', 'data.table', 'dataframe', 'datetime', 'dictionary', 'django', 'dplyr', 'file', 'flask', 'function', 'ggplot2', 'knitr', 'linux', 'list', 'matplotlib', 'numpy', 'pandas', 'performance', 'plot', 'python', 'python-2.7', 'python-3.x', 'r', 'r-faq', 'regex', 'scipy', 'sqlalchemy', 'string', 'unicode', 'unit-testing', 'windows'] \n",
      "\n",
      "f1-score: 0.57\n",
      "precision_score: 0.73\n",
      "recall_score: 0.47\n",
      "Model parameters:  <bound method BaseEstimator.get_params of RandomForestClassifier(max_depth=8)> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_score(RandomForestmodel,X_test,tag[1000:2000],vect_Y,names=True,seuil=0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed19d89",
   "metadata": {},
   "source": [
    "Random Forest avec {'max_depth': 8, 'n_estimators': 100} et avec 32 Tags (et 2000 post) nous avons\n",
    "\n",
    "- f1-score de 57%\n",
    "- précision de 73%\n",
    "- recall de 49%\n",
    "\n",
    "Une moins bonne precision avec un recall équivalent que notre précedent\n",
    "modèle KNN\n",
    "- f1-score de 61%\n",
    "- précision de 78%\n",
    "- recall de 49%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f168f",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "63490eea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T10:06:53.082035Z",
     "start_time": "2021-06-17T10:02:22.028917Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 57s, sys: 35min 55s, total: 49min 52s\n",
      "Wall time: 4min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fedecabre/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.1, hidden_layer_sizes=(100, 100),\n",
       "              learning_rate_init=0.0001, max_iter=500)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 2d 7h 36min 50s pour 20 000 posts\n",
    "# 3min 58s pour 2000 post et 32 tags\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "nb_tag = 32\n",
    "\n",
    "MLPC = MLPClassifier(hidden_layer_sizes=(100,100),\n",
    "                    max_iter=500,\n",
    "                    alpha=0.1, # L2 penalty (regularization term) parameter.\n",
    "                    learning_rate_init=0.0001) #The initial learning rate used. It controls the step-size in updating the weights. \n",
    "\n",
    "vect_Y = CountVectorizer(binary=True,\n",
    "                         token_pattern=rx,\n",
    "                         max_features=nb_tag).fit(tag[2000:])\n",
    "Y_train = vect_Y.transform(tag[2000:]).toarray()\n",
    "\n",
    "MLPC.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e450abda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T10:06:53.311532Z",
     "start_time": "2021-06-17T10:06:53.284909Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding Environment variable in string using python \n",
      "\n",
      "string contain environment mypath homedirdir want parse string look replace string print home osenvironhome myexpandedpath parsestringmypath print path myexpandedpath see output home homeuser path homeuserdirdir way thanks conor \n",
      "\n",
      "expand environment string use python string contain environment mypath homedirdir want parse string look replace string print home osenvironhome myexpandedpath parsestringmypath print path myexpandedpath see output home homeuser path homeuserdirdir way thanks conor\n",
      "\n",
      " Tags prediction :  \n",
      "\n",
      "string 1\n",
      "python 1\n",
      "\n",
      " Tags labels :  \n",
      "\n",
      "python 1\n"
     ]
    }
   ],
   "source": [
    "id_sample = 10\n",
    "new_post = text[id_sample]\n",
    "text_prediction_labels(new_post,vect_X,vect_Y,MLPC,df_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c1585df2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T10:06:53.209370Z",
     "start_time": "2021-06-17T10:06:53.160354Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de Tags pour l'entrainement:  32\n",
      "['arrays', 'class', 'data.table', 'dataframe', 'datetime', 'dictionary', 'django', 'dplyr', 'file', 'flask', 'function', 'ggplot2', 'knitr', 'linux', 'list', 'matplotlib', 'numpy', 'pandas', 'performance', 'plot', 'python', 'python-2.7', 'python-3.x', 'r', 'r-faq', 'regex', 'scipy', 'sqlalchemy', 'string', 'unicode', 'unit-testing', 'windows'] \n",
      "\n",
      "f1-score: 0.77\n",
      "precision_score: 0.88\n",
      "recall_score: 0.69\n",
      "Model parameters:  <bound method BaseEstimator.get_params of MLPClassifier(alpha=0.1, hidden_layer_sizes=(100, 100),\n",
      "              learning_rate_init=0.0001, max_iter=500)> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_score(MLPC,X_test,tag[1000:2000],vect_Y,names=True,seuil=0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f618633",
   "metadata": {},
   "source": [
    "Multi Layer Perceptron avec deux couches denses de 100 elements avec une regularisation Ridge avec alpha = 0.1 et un learning rate initialle de 0.0001 et avec 32 Tags (et 2000 post) nous avons\n",
    "\n",
    "- f1-score de 77%\n",
    "- précision de 88%\n",
    "- recall de 69%\n",
    "\n",
    "Une meilleure performance que notre modèle KNN \n",
    "- f1-score de 61%\n",
    "- précision de 78%\n",
    "- recall de 49%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe7a419",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-17T10:11:24.106Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 2d 7h 36min 50s pour 20 000 posts\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {'alpha' : [0.001,0.01,0.1],\n",
    "              'learning_rate_init' : [0.0001,0.001,0.01],\n",
    "             'hidden_layer_sizes': [(30,),(100,),(30,30),(100,100)]}\n",
    "grid = RandomizedSearchCV(MLPClassifier(max_iter=500), param_grid, cv=5, scoring='f1_micro')\n",
    "\n",
    "best_score = 0\n",
    "best_param = {}\n",
    "best_feature_number = 0\n",
    "\n",
    "for i in [2,32]:\n",
    "    vect_Y = CountVectorizer(binary=True, token_pattern= rx, max_features=i).fit(tag[2000:])\n",
    "    Y_train = vect_Y.transform(tag[2000:]).toarray()\n",
    "    grid.fit(X_train, Y_train)\n",
    "    #if grid.best_score_>best_score:\n",
    "    best_score = grid.best_score_\n",
    "    best_param = grid.best_params_\n",
    "    best_feature_number = i\n",
    "    print(\"Nombre de features: \", best_feature_number)\n",
    "    print(vect_Y.get_feature_names())\n",
    "    print(\"Best cross-validation f1-score: {:.2f}\".format(best_score))\n",
    "    print(\"Best parameters: \", best_param,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e77e49",
   "metadata": {},
   "source": [
    "Résultats avec 2000 post\n",
    "\n",
    "Nombre de features:  2\n",
    "['python', 'r']\n",
    "Best cross-validation f1-score: 0.91\n",
    "Best parameters:  {'learning_rate_init': 0.01, 'hidden_layer_sizes': (30,), 'alpha': 0.001} \n",
    "\n",
    "Nombre de features:  4\n",
    "['django', 'list', 'python', 'r']\n",
    "Best cross-validation f1-score: 0.89\n",
    "Best parameters:  {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100, 100), 'alpha': 0.1} \n",
    "\n",
    "Nombre de features:  8\n",
    "['2', 'django', 'ggplot2', 'list', 'numpy', 'python', 'r', 'string']\n",
    "Best cross-validation f1-score: 0.85\n",
    "Best parameters:  {'learning_rate_init': 0.01, 'hidden_layer_sizes': (100, 100), 'alpha': 0.001} \n",
    "\n",
    "Nombre de features:  16\n",
    "['2', '3', 'data', 'dataframe', 'dictionary', 'django', 'ggplot2', 'list', 'matplotlib', 'numpy', 'pandas', 'python', 'r', 'regex', 'string', 'x']\n",
    "Best cross-validation f1-score: 0.79\n",
    "Best parameters:  {'learning_rate_init': 0.01, 'hidden_layer_sizes': (100, 100), 'alpha': 0.1} \n",
    "\n",
    "Nombre de features:  32\n",
    "['2', '3', '7', 'c', 'data', 'dataframe', 'datetime', 'dictionary', 'django', 'dplyr', 'exception', 'faq', 'file', 'ggplot2', 'import', 'list', 'markdown', 'matplotlib', 'matrix', 'numpy', 'pandas', 'plot', 'python', 'r', 'regex', 'scipy', 'sqlalchemy', 'string', 'table', 'testing', 'unit', 'x']\n",
    "Best cross-validation f1-score: 0.74\n",
    "Best parameters:  {'learning_rate_init': 0.001, 'hidden_layer_sizes': (100,), 'alpha': 0.1} \n",
    "\n",
    "CPU times: user 4h 27min 25s, sys: 11h 42min 22s, total: 16h 9min 47s\n",
    "Wall time: 1h 24min 31s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93be113e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-17T07:22:52.011Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(vect_Y_32, open('API/models/vect_Y_32.pickle', 'wb'))\n",
    "pickle.dump(MLP_clf, open('API/models/MLP_clf.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b7868",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-17T07:22:52.015Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "clf=grid.best_estimator_\n",
    "\n",
    "pickle.dump(clf, open('models/final_prediction.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4774c5c9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-17T07:22:52.013Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "id_sample = 1002\n",
    "new_post = text_train[id_sample]\n",
    "text_prediction_labels(new_post,vect_X,vect_Y,MLP_clf,df_questions)\n",
    "\n",
    "y_train_MLP_pred = MLP_clf.predict(X_train)\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F1 score : ')\n",
    "y_train_MLP_pred_ones = (y_train_MLP_pred >0).astype(int)\n",
    "f1_score(Y_train, y_train_MLP_pred_ones, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80aa387",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### pour 20 000 post\n",
    "Cross validation CV=5\n",
    "MLPClassifier(max_iter=500), param_grid, cv=5, scoring='f1_micro')\n",
    "\n",
    "Best cross-validation score: 0.87\n",
    "Best parameters:  {'learning_rate_init': 0.001, 'alpha': 0.1}\n",
    "Best nombre de features:  2\n",
    "['python', 'r']\n",
    "\n",
    "Best cross-validation score: 0.88\n",
    "Best parameters:  {'learning_rate_init': 0.0001, 'alpha': 0.1}\n",
    "Best nombre de features:  4\n",
    "['django', 'ggplot2', 'python', 'r']\n",
    "\n",
    "Best cross-validation score: 0.92\n",
    "Best parameters:  {'learning_rate_init': 0.0001, 'alpha': 0.1}\n",
    "Best nombre de features:  8\n",
    "['dataframe', 'django', 'ggplot2', 'list', 'numpy', 'python', 'r', 'string']\n",
    "\n",
    "Best cross-validation score: 0.87\n",
    "Best parameters:  {'learning_rate_init': 0.0001, 'alpha': 0.1}\n",
    "Best nombre de features:  16\n",
    "['2', '3', 'data', 'dataframe', 'dictionary', 'django', 'ggplot2', 'list', 'matplotlib', 'numpy', 'pandas', 'python', 'r', 'regex', 'string', 'x']\n",
    "\n",
    "Best cross-validation score: 0.91\n",
    "Best parameters:  {'learning_rate_init': 0.0001, 'alpha': 0.1}\n",
    "Best nombre de features:  32\n",
    "['2', '3', '7', 'class', 'data', 'dataframe', 'datetime', 'dictionary', 'django', 'dplyr', 'faq', 'file', 'flask', 'function', 'ggplot2', 'import', 'list', 'matplotlib', 'models', 'numpy', 'pandas', 'performance', 'plot', 'python', 'r', 'regex', 'scipy', 'sqlalchemy', 'string', 'table', 'testing', 'x']\n",
    "\n",
    "CPU times: user 13d 12h 11min 43s, sys: 2h 41min 2s, total: 13d 14h 52min 45s\n",
    "Wall time: 2d 7h 36min 50s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9607a",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}