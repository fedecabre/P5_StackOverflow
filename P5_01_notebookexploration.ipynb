{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, the end-goal of this notebook was to preprocess data for topic detection and tag classification.  \n",
    "I tried to explain why I choose to diverge or not from a \"classical\" preprocess on this particular case (see optional & specific)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Étapes de prétraitement\n",
    "\n",
    "**1) Suppression du bruit**\n",
    "\n",
    "1. Suppression du formatage  HTML\n",
    "2. Suppression des contractions\n",
    "3. La correction orthographique\n",
    "4. Mettre en minuscule le texte\n",
    "\n",
    "**2) Suppression des caractères simples**\n",
    "\n",
    "1. Suppression de la ponctuation, des caractères spéciaux et des nombres\n",
    "2. Suppression d'un seul caractère (facultatif et spécifique)\n",
    "\n",
    "**3) Suppression de StopWords**\n",
    "\n",
    "1. Suppression du mot le plus fréquent\n",
    "2. Suppression d'un certain type de mot (facultatif et spécifique)\n",
    "\n",
    "**4) Steming / Lemmatisation**\n",
    "\n",
    "1. Steming\n",
    "2. Lemmatisation\n",
    "\n",
    "\n",
    "Ce pré-processus est utilisé pour effectuer une simple détection de sujet (LDA, NMF, etc.) ou une classification, des informations nécessaires à certaines analyses peuvent être perdues.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.1 Vocabulaire\n",
    "Si vous êtes nouveau dans la PNL, voici une petite liste de concepts utilisés dans ce cahier.\n",
    "\n",
    "Tokenize: \"Processus de conversion d'une chaîne en une liste de sous-chaînes, appelées tokens.\"\n",
    "\n",
    "Normalisation du texte: \"Processus de transformation d'un texte en une seule forme canonique qu'il n'aurait peut-être pas eu auparavant (par exemple, mettre en miniscule le texte, supprimer les contractions, correction orthographique, stemming / lemmatisation, etc.). La normalisation du texte nécessite de savoir quel type de texte doit être normalisée et comment elle doit être traitée par la suite; il n’existe pas de procédure de normalisation universelle. \"\n",
    "\n",
    "Suppression du bruit: \"Processus de suppression de tout élément susceptible d'interférer avec votre analyse (par exemple, suppression du code HTML, mettre en minuscule le texte, suppression de la ponctuation / du caractère spécial, etc.)\n",
    "\n",
    "Stemming: \"Processus de réduction des mots à leur racine , base ou forme de racine - généralement une forme de mot écrit (\"fishing\", \"fished\", and \"fisher\" to the stem \"fish\").\"\n",
    "\n",
    "Lématisation: \"Processus de regroupement des formes fléchies d'un mot afin qu'elles puissent être analysées comme un seul élément, identifié par le lemme du mot, ou par la forme du dictionnaire (ie: \"walking\" to \"walk\", \"better\" to \"good\").\"\n",
    "\n",
    "StopWord: \"Mots qui sont filtrés avant ou après le traitement des données en langage naturel (texte). Les mots d'arrêt font généralement référence aux mots les plus courants dans une langue (des mots comme \"The\",\"a\", etc. en anglais).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Libraries and Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:17.921220Z",
     "start_time": "2021-05-27T11:27:11.998089Z"
    },
    "_kg_hide-input": false,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /home/fedecabre/anaconda3/envs/P5_StackOverflow/lib/python3.9/site-packages (0.0.1)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /home/fedecabre/anaconda3/envs/P5_StackOverflow/lib/python3.9/site-packages (from bs4) (4.9.3)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/fedecabre/anaconda3/envs/P5_StackOverflow/lib/python3.9/site-packages (from beautifulsoup4->bs4) (2.2.1)\r\n",
      "Requirement already satisfied: contractions in /home/fedecabre/anaconda3/envs/P5_StackOverflow/lib/python3.9/site-packages (0.0.49)\r\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /home/fedecabre/anaconda3/envs/P5_StackOverflow/lib/python3.9/site-packages (from contractions) (0.0.21)\r\n",
      "Requirement already satisfied: pyahocorasick in /home/fedecabre/anaconda3/envs/P5_StackOverflow/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (1.4.2)\r\n",
      "Requirement already satisfied: anyascii in /home/fedecabre/anaconda3/envs/P5_StackOverflow/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (0.2.0)\r\n",
      "Requirement already satisfied: autocorrect in /home/fedecabre/anaconda3/envs/P5_StackOverflow/lib/python3.9/site-packages (2.5.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install bs4\n",
    "# ! pip install pycontractions # The package has a depencies that have not been updated, so I couldn't use it.\n",
    "! pip install contractions\n",
    "! pip install autocorrect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.202497Z",
     "start_time": "2021-05-27T11:27:17.925120Z"
    }
   },
   "outputs": [],
   "source": [
    "# generic librairies\n",
    "import pandas as pd\n",
    "\n",
    "# Text librairies\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import contractions\n",
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.205600Z",
     "start_time": "2021-05-27T11:27:19.203632Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://numpy.org/devdocs/user/basics.types.html\n",
    "\n",
    "dtypes_questions = {'Id':'int32', 'Score': 'int16', 'Title': 'str', 'Body': 'str'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.231590Z",
     "start_time": "2021-05-27T11:27:19.206697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 ms, sys: 4.29 ms, total: 18.1 ms\n",
      "Wall time: 17.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_questions = pd.read_csv('input/QueryResults first 50000 post.csv',\n",
    "                           usecols=['Id', 'Score', 'Title', 'Body'], \n",
    "                           encoding = \"ISO-8859-1\",\n",
    "                           dtype=dtypes_questions,\n",
    "                           nrows=1000\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.243571Z",
     "start_time": "2021-05-27T11:27:19.233078Z"
    }
   },
   "outputs": [],
   "source": [
    "df_questions[['Title', 'Body']] = df_questions[[\n",
    "    'Title', 'Body'\n",
    "]].applymap(lambda x: str(x).encode(\"utf-8\", errors='surrogatepass').decode(\n",
    "    \"ISO-8859-1\", errors='surrogatepass'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.263161Z",
     "start_time": "2021-05-27T11:27:19.245388Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove all questions that have a negative score\n",
    "df_questions = df_questions[df_questions[\"Score\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.328669Z",
     "start_time": "2021-05-27T11:27:19.264551Z"
    }
   },
   "outputs": [],
   "source": [
    "spell = Speller()\n",
    "token = ToktokTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "charac = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~0123456789'\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "adjective_tag_list = {'JJ', 'JJR', 'JJS', 'RBR', 'RBS'}  # List of Adjective's tag from nltk package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tag list**  \n",
    "List of tag use in the tagger (pos_tag function) from NLTK:\n",
    "https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.342111Z",
     "start_time": "2021-05-27T11:27:19.329677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 990 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Id      990 non-null    int32 \n",
      " 1   Score   990 non-null    int16 \n",
      " 2   Body    990 non-null    object\n",
      " 3   Title   990 non-null    object\n",
      "dtypes: int16(1), int32(1), object(2)\n",
      "memory usage: 29.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_questions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Suppression du bruit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La suppression du bruit consiste à supprimer tout ce qui peut interférer avec votre analyse de texte. C'est comme l'étape de nettoyage des données pour un projet ML classique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Suppression du code  HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.350625Z",
     "start_time": "2021-05-27T11:27:19.343079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'<p>For a table like this:</p>\\n\\n<pre><code>CREATE TABLE binary_data (\\n    id INT(4) NOT NULL AUTO_INCREMENT PRIMARY KEY,\\n    description CHAR(50),\\n    bin_data LONGBLOB,\\n    filename CHAR(50),\\n    filesize CHAR(50),\\n    filetype CHAR(50)\\n);\\n</code></pre>\\n\\n<p>Here is a PHP example:</p>\\n\\n<pre><code>&lt;?php\\n    // store.php3 - by Florian Dittmer &lt;dittmer@gmx.net&gt;\\n    // Example php script to demonstrate the storing of binary files into\\n    // an sql database. More information can be found at http://www.phpbuilder.com/\\n?&gt;\\n\\n&lt;html&gt;\\n    &lt;head&gt;&lt;title&gt;Store binary data into SQL Database&lt;/title&gt;&lt;/head&gt;\\n\\n    &lt;body&gt;\\n        &lt;?php\\n            // Code that will be executed if the form has been submitted:\\n\\n            if ($submit) {\\n                // Connect to the database (you may have to adjust\\n                // the hostname, username or password).\\n\\n                mysql_connect(\"localhost\", \"root\", \"password\");\\n                mysql_select_db(\"binary_data\");\\n\\n                $data = mysql_real_escape_string(fread(fopen($form_data, \"r\"), filesize($form_data)));\\n\\n                $result = mysql_query(\"INSERT INTO binary_data (description, bin_data, filename, filesize, filetype) \".\\n                                    \"VALUES (\\'$form_description\\', \\'$data\\', \\'$form_data_name\\', \\'$form_data_size\\', \\'$form_data_type\\')\");\\n\\n                $id= mysql_insert_id();\\n                print \"&lt;p&gt;This file has the following Database ID: &lt;b&gt;$id&lt;/b&gt;\";\\n\\n                mysql_close();\\n            } else {\\n\\n                // else show the form to submit new data:\\n        ?&gt;\\n        &lt;form method=\"post\" action=\"&lt;?php echo $PHP_SELF; ?&gt;\" enctype=\"multipart/form-data\"&gt;\\n            File Description:&lt;br&gt;\\n            &lt;input type=\"text\" name=\"form_description\"  size=\"40\"&gt;\\n            &lt;input type=\"hidden\" name=\"MAX_FILE_SIZE\" value=\"1000000\"&gt;\\n            &lt;br&gt;File to upload/store in database:&lt;br&gt;\\n            &lt;input type=\"file\" name=\"form_data\"  size=\"40\"&gt;\\n            &lt;p&gt;&lt;input type=\"submit\" name=\"submit\" value=\"submit\"&gt;\\n        &lt;/form&gt;\\n\\n        &lt;?php\\n            }\\n        ?&gt;\\n    &lt;/body&gt;\\n&lt;/html&gt;\\n</code></pre>\\n'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.697813Z",
     "start_time": "2021-05-27T11:27:19.351825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 394 ms, sys: 299 µs, total: 394 ms\n",
      "Wall time: 393 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Parse question and title then return only the text\n",
    "df_questions['Body'] = df_questions['Body'].apply(\n",
    "    lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
    "df_questions['Title'] = df_questions['Title'].apply(\n",
    "    lambda x: BeautifulSoup(x, 'html.parser').get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup nous permet de supprimer efficacement la plupart du code html mais pas tout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.701602Z",
     "start_time": "2021-05-27T11:27:19.698811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'For a table like this:\\nCREATE TABLE binary_data (\\n    id INT(4) NOT NULL AUTO_INCREMENT PRIMARY KEY,\\n    description CHAR(50),\\n    bin_data LONGBLOB,\\n    filename CHAR(50),\\n    filesize CHAR(50),\\n    filetype CHAR(50)\\n);\\n\\nHere is a PHP example:\\n<?php\\n    // store.php3 - by Florian Dittmer <dittmer@gmx.net>\\n    // Example php script to demonstrate the storing of binary files into\\n    // an sql database. More information can be found at http://www.phpbuilder.com/\\n?>\\n\\n<html>\\n    <head><title>Store binary data into SQL Database</title></head>\\n\\n    <body>\\n        <?php\\n            // Code that will be executed if the form has been submitted:\\n\\n            if ($submit) {\\n                // Connect to the database (you may have to adjust\\n                // the hostname, username or password).\\n\\n                mysql_connect(\"localhost\", \"root\", \"password\");\\n                mysql_select_db(\"binary_data\");\\n\\n                $data = mysql_real_escape_string(fread(fopen($form_data, \"r\"), filesize($form_data)));\\n\\n                $result = mysql_query(\"INSERT INTO binary_data (description, bin_data, filename, filesize, filetype) \".\\n                                    \"VALUES (\\'$form_description\\', \\'$data\\', \\'$form_data_name\\', \\'$form_data_size\\', \\'$form_data_type\\')\");\\n\\n                $id= mysql_insert_id();\\n                print \"<p>This file has the following Database ID: <b>$id</b>\";\\n\\n                mysql_close();\\n            } else {\\n\\n                // else show the form to submit new data:\\n        ?>\\n        <form method=\"post\" action=\"<?php echo $PHP_SELF; ?>\" enctype=\"multipart/form-data\">\\n            File Description:<br>\\n            <input type=\"text\" name=\"form_description\"  size=\"40\">\\n            <input type=\"hidden\" name=\"MAX_FILE_SIZE\" value=\"1000000\">\\n            <br>File to upload/store in database:<br>\\n            <input type=\"file\" name=\"form_data\"  size=\"40\">\\n            <p><input type=\"submit\" name=\"submit\" value=\"submit\">\\n        </form>\\n\\n        <?php\\n            }\\n        ?>\\n    </body>\\n</html>\\n\\n'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous devons donc supprimer le reste ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.711550Z",
     "start_time": "2021-05-27T11:27:19.702841Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\" mettre la déf de la fonction\"\"\"\n",
    "    text = re.sub(r\"\\'\", \"'\", text) # match all literal apostrophe pattern then replace them by a single whitespace\n",
    "    text = re.sub(r\"\\n\", \" \", text) # match all literal Line Feed (New line) pattern then replace them by a single whitespace\n",
    "    text = re.sub(r\"\\xa0\", \" \", text) # match all literal non-breakable space pattern then replace them by a single whitespace\n",
    "    text = re.sub('\\s+', ' ', text) # match all one or more whitespace then replace them by a single whitespace\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.755605Z",
     "start_time": "2021-05-27T11:27:19.712850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.9 ms, sys: 456 µs, total: 40.3 ms\n",
      "Wall time: 41 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_questions['Title'] = df_questions['Title'].apply(lambda x: clean_text(x)) \n",
    "df_questions['Body'] = df_questions['Body'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.759198Z",
     "start_time": "2021-05-27T11:27:19.756621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'For a table like this: CREATE TABLE binary_data ( id INT(4) NOT NULL AUTO_INCREMENT PRIMARY KEY, description CHAR(50), bin_data LONGBLOB, filename CHAR(50), filesize CHAR(50), filetype CHAR(50) ); Here is a PHP example: <?php // store.php3 - by Florian Dittmer <dittmer@gmx.net> // Example php script to demonstrate the storing of binary files into // an sql database. More information can be found at http://www.phpbuilder.com/ ?> <html> <head><title>Store binary data into SQL Database</title></head> <body> <?php // Code that will be executed if the form has been submitted: if ($submit) { // Connect to the database (you may have to adjust // the hostname, username or password). mysql_connect(\"localhost\", \"root\", \"password\"); mysql_select_db(\"binary_data\"); $data = mysql_real_escape_string(fread(fopen($form_data, \"r\"), filesize($form_data))); $result = mysql_query(\"INSERT INTO binary_data (description, bin_data, filename, filesize, filetype) \". \"VALUES (\\'$form_description\\', \\'$data\\', \\'$form_data_name\\', \\'$form_data_size\\', \\'$form_data_type\\')\"); $id= mysql_insert_id(); print \"<p>This file has the following Database ID: <b>$id</b>\"; mysql_close(); } else { // else show the form to submit new data: ?> <form method=\"post\" action=\"<?php echo $PHP_SELF; ?>\" enctype=\"multipart/form-data\"> File Description:<br> <input type=\"text\" name=\"form_description\" size=\"40\"> <input type=\"hidden\" name=\"MAX_FILE_SIZE\" value=\"1000000\"> <br>File to upload/store in database:<br> <input type=\"file\" name=\"form_data\" size=\"40\"> <p><input type=\"submit\" name=\"submit\" value=\"submit\"> </form> <?php } ?> </body> </html>'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Suppression des contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.768347Z",
     "start_time": "2021-05-27T11:27:19.760220Z"
    }
   },
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "    \"\"\"expand shortened words, e.g. 'don't' to 'do not'\"\"\"\n",
    "    text = contractions.fix(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.820366Z",
     "start_time": "2021-05-27T11:27:19.769476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.8 ms, sys: 15 µs, total: 52.8 ms\n",
      "Wall time: 52.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_questions['Title'] = df_questions['Title'].apply(lambda x: expand_contractions(x)) \n",
    "df_questions['Body'] = df_questions['Body'].apply(lambda x: expand_contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.823589Z",
     "start_time": "2021-05-27T11:27:19.821272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'For a table like this: CREATE TABLE binary_data ( id INT(4) NOT NULL AUTO_INCREMENT PRIMARY KEY, description CHAR(50), bin_data LONGBLOB, filename CHAR(50), filesize CHAR(50), filetype CHAR(50) ); Here is a PHP example: <?php // store.php3 - by Florian Dittmer <dittmer@gmx.net> // Example php script to demonstrate the storing of binary files into // an sql database. More information can be found at http://www.phpbuilder.com/ ?> <html> <head><title>Store binary data into SQL Database</title></head> <body> <?php // Code that will be executed if the form has been submitted: if ($submit) { // Connect to the database (you may have to adjust // the hostname, username or password). mysql_connect(\"localhost\", \"root\", \"password\"); mysql_select_db(\"binary_data\"); $data = mysql_real_escape_string(fread(fopen($form_data, \"r\"), filesize($form_data))); $result = mysql_query(\"INSERT INTO binary_data (description, bin_data, filename, filesize, filetype) \". \"VALUES (\\'$form_description\\', \\'$data\\', \\'$form_data_name\\', \\'$form_data_size\\', \\'$form_data_type\\')\"); $id= mysql_insert_id(); print \"<p>This file has the following Database ID: <b>$id</b>\"; mysql_close(); } else { // else show the form to submit new data: ?> <form method=\"post\" action=\"<?php echo $PHP_SELF; ?>\" enctype=\"multipart/form-data\"> File Description:<br> <input type=\"text\" name=\"form_description\" size=\"40\"> <input type=\"hidden\" name=\"MAX_FILE_SIZE\" value=\"1000000\"> <br>File to upload/store in database:<br> <input type=\"file\" name=\"form_data\" size=\"40\"> <p><input type=\"submit\" name=\"submit\" value=\"submit\"> </form> <?php } ?> </body> </html>'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. La correction orthographique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pour 1000 entrées cette correction prends 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.831988Z",
     "start_time": "2021-05-27T11:27:19.824389Z"
    }
   },
   "outputs": [],
   "source": [
    "def autocorrect(text):\n",
    "    words = token.tokenize(text)\n",
    "    words_correct = [spell(w) for w in words]\n",
    "    return ' '.join(map(str, words_correct)) # Return the text untokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.840528Z",
     "start_time": "2021-05-27T11:27:19.832771Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df_questions['Title'] = df_questions['Title'].apply(lambda x: autocorrect(x)) \n",
    "#df_questions['Body'] = df_questions['Body'].apply(lambda x: autocorrect(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Mettre en minuscule le texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.851493Z",
     "start_time": "2021-05-27T11:27:19.841333Z"
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Je choisis d'abaisser le texte après le paquet de contractions car celui-ci peut remettre des lettres majuscules lors de la suppression des contractions. La mise en minuscule du texte est une étape classique et utile de la suppression du bruit ou de la normalisation du texte car elle réduit le vocabulaire, normalise le texte et ne coûte presque rien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.860550Z",
     "start_time": "2021-05-27T11:27:19.854232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.13 ms, sys: 11 µs, total: 4.14 ms\n",
      "Wall time: 3.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_questions['Title'] = df_questions['Title'].str.lower()\n",
    "df_questions['Body'] = df_questions['Body'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_questions['Body'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Suppression des caractères"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Suppression de la ponctuation, des caractères spéciaux et des nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.868801Z",
     "start_time": "2021-05-27T11:27:19.862864Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-85914441bee8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"<ipython-input-28-85914441bee8>\"\u001B[0;36m, line \u001B[0;32m1\u001B[0m\n\u001B[0;31m    TOUS les caractères non alphabétiques ont été supprimés (y compris la ponctuation, les nombres et les caractères spéciaux). Ainsi, je ne considère pas les mots importants qui peuvent contenir des caractères spéciaux (comme \"C #\" en programmation).\u001B[0m\n\u001B[0m         ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "TOUS les caractères non alphabétiques ont été supprimés (y compris la ponctuation, les nombres et les caractères spéciaux). Ainsi, je ne considère pas les mots importants qui peuvent contenir des caractères spéciaux (comme \"C #\" en programmation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.955569Z",
     "start_time": "2021-05-27T11:27:19.869833Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation_and_number(text):\n",
    "    \"\"\"remove all punctuation and number\"\"\"\n",
    "    return text.translate(str.maketrans(\" \", \" \", charac)) \n",
    "\n",
    "def remove_non_alphabetical_character(text):\n",
    "    \"\"\"remove all non-alphabetical character\"\"\"\n",
    "    text = re.sub(\"[^a-z]+\", \" \", text) # remove all non-alphabetical character\n",
    "    text = re.sub(\"\\s+\", \" \", text) # remove whitespaces left after the last operation\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.959591Z",
     "start_time": "2021-05-27T11:27:19.956838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'i am looking for the fastest way to obtain the value of ã\\x8fâ\\x80, as a personal challenge. more specifically, i am using ways that do not involve using #define constants like m_pi, or hard-coding the number in. the program below tests the various ways i know of. the inline assembly version is, in theory, the fastest option, though clearly not portable. i have included it as a baseline to compare against the other versions. in my tests, with built-ins, the 4 * atan(1) version is fastest on gcc 4.2, because it auto-folds the atan(1) into a constant. with -fno-builtin specified, the atan2(0, -1) version is fastest. here is the main testing program (pitimes.c): #include <math.h> #include <stdio.h> #include <time.h> #define iters 10000000 #define testwith(x) { \\\\ diff = 0.0; \\\\ time1 = clock(); \\\\ for (i = 0; i < iters; ++i) \\\\ diff += (x) - m_pi; \\\\ time2 = clock(); \\\\ printf(\"%s\\\\t=> %e, time => %f\\\\n\", #x, diff, diffclock(time2, time1)); \\\\ } static inline double diffclock(clock_t time1, clock_t time0) { return (double) (time1 - time0) / clocks_per_sec; } int main() { int i; clock_t time1, time2; double diff; /* warmup. the atan2 case catches gcc\\'s atan folding (which would * optimise the ``4 * atan(1) - m_pi\\'\\' to a no-op), if -fno-builtin * is not used. */ testwith(4 * atan(1)) testwith(4 * atan2(1, 1)) #if defined(__gnuc__) && (defined(__i386__) || defined(__amd64__)) extern double fldpi(); testwith(fldpi()) #endif /* actual tests start here. */ testwith(atan2(0, -1)) testwith(acos(-1)) testwith(2 * asin(1)) testwith(4 * atan2(1, 1)) testwith(4 * atan(1)) return 0; } and the inline assembly stuff (fldpi.c) that will only work for x86 and x64 systems: double fldpi() { double pi; asm(\"fldpi\" : \"=t\" (pi)); return pi; } and a build script that builds all the configurations i am testing (build.sh): #!/bin/sh gcc -o3 -wall -c -m32 -of fldpi-32.of fldpi.c gcc -o3 -wall -c -m64 -of fldpi-64.of fldpi.c gcc -o3 -wall -ffast-math -m32 -of pitimes1-32 pitimes.c fldpi-32.of gcc -o3 -wall -m32 -of pitimes2-32 pitimes.c fldpi-32.of -lm gcc -o3 -wall -fno-builtin -m32 -of pitimes3-32 pitimes.c fldpi-32.of -lm gcc -o3 -wall -ffast-math -m64 -of pitimes1-64 pitimes.c fldpi-64.of -lm gcc -o3 -wall -m64 -of pitimes2-64 pitimes.c fldpi-64.of -lm gcc -o3 -wall -fno-builtin -m64 -of pitimes3-64 pitimes.c fldpi-64.of -lm apart from testing between various compiler flags (i have compared 32-bit against 64-bit too because the optimizations are different), i have also tried switching the order of the tests around. but still, the atan2(0, -1) version still comes out on top every time.'"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Suppression de la présence d'un seul caractère\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je choisis de supprimer un seul caractère car lorsque nous faisons de la programmation, nous utilisons souvent un seul caractère alphabétique comme nom de variable (\"x\", \"y\", \"z\", etc.). Et j'ai observé que lorsque j'ai essayé de détecter des sujets sans les supprimer, j'ai trouvé beaucoup de sujets avec eux! Et même un sujet que je pourrais nommer \"Nom de variable\" ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:19.968011Z",
     "start_time": "2021-05-27T11:27:19.960541Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_single_letter(text):\n",
    "    \"\"\"remove single alphabetical character\"\"\"\n",
    "    text = re.sub(r\"\\b\\w{1}\\b\", \"\", text) # remove all single letter\n",
    "    text = re.sub(\"\\s+\", \" \", text) # remove whitespaces left after the last operation\n",
    "    text = text.strip(\" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:20.021702Z",
     "start_time": "2021-05-27T11:27:19.969313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.9 ms, sys: 0 ns, total: 51.9 ms\n",
      "Wall time: 51.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_questions['Title'] = df_questions['Title'].apply(lambda x: remove_single_letter(x)) \n",
    "df_questions['Body'] = df_questions['Body'].apply(lambda x: remove_single_letter(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:20.025027Z",
     "start_time": "2021-05-27T11:27:20.022649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'am looking for the fastest way to obtain the value of \\x8f\\x80, as personal challenge. more specifically, am using ways that do not involve using #define constants like m_pi, or hard-coding the number in. the program below tests the various ways know of. the inline assembly version is, in theory, the fastest option, though clearly not portable. have included it as baseline to compare against the other versions. in my tests, with built-ins, the * atan() version is fastest on gcc ., because it auto-folds the atan() into constant. with -fno-builtin specified, the atan2(, -) version is fastest. here is the main testing program (pitimes.): #include <math.> #include <stdio.> #include <time.> #define iters 10000000 #define testwith() { \\\\ diff = .; \\\\ time1 = clock(); \\\\ for ( = ; < iters; ++) \\\\ diff += () - m_pi; \\\\ time2 = clock(); \\\\ printf(\"%\\\\=> %, time => %\\\\\", #, diff, diffclock(time2, time1)); \\\\ } static inline double diffclock(clock_t time1, clock_t time0) { return (double) (time1 - time0) / clocks_per_sec; } int main() { int ; clock_t time1, time2; double diff; /* warmup. the atan2 case catches gcc\\' atan folding (which would * optimise the `` * atan() - m_pi\\'\\' to no-op), if -fno-builtin * is not used. */ testwith( * atan()) testwith( * atan2(, )) #if defined(__gnuc__) && (defined(__i386__) || defined(__amd64__)) extern double fldpi(); testwith(fldpi()) #endif /* actual tests start here. */ testwith(atan2(, -)) testwith(acos(-)) testwith( * asin()) testwith( * atan2(, )) testwith( * atan()) return ; } and the inline assembly stuff (fldpi.) that will only work for x86 and x64 systems: double fldpi() { double pi; asm(\"fldpi\" : \"=\" (pi)); return pi; } and build script that builds all the configurations am testing (build.sh): #!/bin/sh gcc -o3 -wall - -m32 -of fldpi-32.of fldpi. gcc -o3 -wall - -m64 -of fldpi-64.of fldpi. gcc -o3 -wall -ffast-math -m32 -of pitimes1-32 pitimes. fldpi-32.of gcc -o3 -wall -m32 -of pitimes2-32 pitimes. fldpi-32.of -lm gcc -o3 -wall -fno-builtin -m32 -of pitimes3-32 pitimes. fldpi-32.of -lm gcc -o3 -wall -ffast-math -m64 -of pitimes1-64 pitimes. fldpi-64.of -lm gcc -o3 -wall -m64 -of pitimes2-64 pitimes. fldpi-64.of -lm gcc -o3 -wall -fno-builtin -m64 -of pitimes3-64 pitimes. fldpi-64.of -lm apart from testing between various compiler flags ( have compared 32-bit against 64-bit too because the optimizations are different), have also tried switching the order of the tests around. but still, the atan2(, -) version still comes out on top every time.'"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Suppression des stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Removing most frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer les mots les plus fréquents est une étape classique de la NLP. Les mots les plus fréquents n'ajoutent pas beaucoup d'informations dans la plupart des cas (puisqu'ils sont dans presque toutes les phrases). En les supprimant, vous créez plus d'\"espace\" pour les autres mots qui peuvent avoir des informations plus utiles.\n",
    "Vous pouvez utiliser des listes prédéfinies à partir de bibliothèques telles que SciKit-Learn, NLTK et autres. Mais sachez que ces listes peuvent être plus problématiques qu'utiles (en particulier la liste scikit-learn, voir [Stop Word Lists in Free Open-source Software Packages](https://www.aclweb.org/anthology/W18-2502.pdf) pour plus d'informations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:20.033636Z",
     "start_time": "2021-05-27T11:27:20.025899Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"remove common words in english by using nltk.corpus's list\"\"\"\n",
    "    words = token.tokenize(text)\n",
    "    filtered = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    return ' '.join(map(str, filtered)) # Return the text untokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:20.185629Z",
     "start_time": "2021-05-27T11:27:20.035064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 175 ms, sys: 0 ns, total: 175 ms\n",
      "Wall time: 174 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_questions['Title'] = df_questions['Title'].apply(lambda x: remove_stopwords(x))\n",
    "df_questions['Body'] = df_questions['Body'].apply(lambda x: remove_stopwords(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:20.189373Z",
     "start_time": "2021-05-27T11:27:20.186748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'looking fastest way obtain value \\x8f\\x80 , personal challenge. specifically , using ways involve using #define constants like m_pi , hard-coding number in. program tests various ways know of. inline assembly version , theory , fastest option , though clearly portable. included baseline compare versions. tests , built-ins , * atan( ) version fastest gcc . , auto-folds atan( ) constant. -fno-builtin specified , atan2( , - ) version fastest. main testing program ( pitimes. ) : #include <math.> #include <stdio.> #include <time.> #define iters 10000000 #define testwith( ) { \\\\ diff = . ; \\\\ time1 = clock( ) ; \\\\ ( = ; < iters ; ++ ) \\\\ diff += ( ) - m_pi ; \\\\ time2 = clock( ) ; \\\\ printf( \" % \\\\=> % , time => % \\\\ \" , # , diff , diffclock( time2 , time1 ) ) ; \\\\ } static inline double diffclock( clock_t time1 , clock_t time0 ) { return ( double ) ( time1 - time0 ) / clocks_per_sec ; } int main( ) { int ; clock_t time1 , time2 ; double diff ; / * warmup. atan2 case catches gcc \\' atan folding ( would * optimise ` ` * atan( ) - m_pi \\' \\' no-op ) , -fno-builtin * used. */ testwith( * atan( ) ) testwith( * atan2( , ) ) #if defined( __gnuc__ ) &&amp; ( defined( __i386__ ) &#124; &#124; defined( __amd64__ ) ) extern double fldpi( ) ; testwith( fldpi( ) ) #endif / * actual tests start here. */ testwith( atan2( , - ) ) testwith( acos( - ) ) testwith( * asin( ) ) testwith( * atan2( , ) ) testwith( * atan( ) ) return ; } inline assembly stuff ( fldpi. ) work x86 x64 systems : double fldpi( ) { double pi ; asm( \" fldpi \" : \" = \" ( pi ) ) ; return pi ; } build script builds configurations testing ( build.sh ) : # ! / bin/sh gcc -o3 -wall - -m32 -of fldpi-32.of fldpi. gcc -o3 -wall - -m64 -of fldpi-64.of fldpi. gcc -o3 -wall -ffast-math -m32 -of pitimes1-32 pitimes. fldpi-32.of gcc -o3 -wall -m32 -of pitimes2-32 pitimes. fldpi-32.of -lm gcc -o3 -wall -fno-builtin -m32 -of pitimes3-32 pitimes. fldpi-32.of -lm gcc -o3 -wall -ffast-math -m64 -of pitimes1-64 pitimes. fldpi-64.of -lm gcc -o3 -wall -m64 -of pitimes2-64 pitimes. fldpi-64.of -lm gcc -o3 -wall -fno-builtin -m64 -of pitimes3-64 pitimes. fldpi-64.of -lm apart testing various compiler flags ( compared 32-bit 64-bit optimizations different ) , also tried switching order tests around. still , atan2( , - ) version still comes top every time .'"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Removing adjectives (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je choisis de supprimer les adjectifs en plus de la liste NLTK. Pourquoi? Tout simplement parce que lorsque j'ai d'abord essayé de faire une détection de sujet dans un cahier suivant celui-ci et cela améliore ma détection de sujet. Je pensais aussi que les adjectifs n'ajouteraient aucune information utile. En même temps, je pourrais aussi supprimer des verbes avec le même raisonnement. Mais je ne l'ai pas fait parce que l'ensemble de données StackOverflow concerne la programmation. Et en programmation, nous avons beaucoup de verbes, ou de mots qui peuvent être interprétés comme un verbe, qui peuvent être importants (\"return\", \"get\", \"request\", \"replace\", etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:20.199901Z",
     "start_time": "2021-05-27T11:27:20.190406Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_by_tag(text, undesired_tag):\n",
    "    \"\"\"remove all words by using ntk tag (adjectives, verbs, etc.)\"\"\"\n",
    "    words = token.tokenize(text) # Tokenize each words\n",
    "    words_tagged = nltk.pos_tag(tokens=words, tagset=None, lang='eng') # Tag each words and return a list of tuples (e.g. (\"have\", \"VB\"))\n",
    "    filtered = [w[0] for w in words_tagged if w[1] not in undesired_tag] # Select all words that don't have the undesired tags\n",
    "    \n",
    "    return ' '.join(map(str, filtered)) # Return the text untokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:22.793791Z",
     "start_time": "2021-05-27T11:27:20.201339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.98 s, sys: 38.3 ms, total: 3.02 s\n",
      "Wall time: 3.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_questions['Title'] = df_questions['Title'].apply(\n",
    "    lambda x: remove_by_tag(x, adjective_tag_list))\n",
    "df_questions['Body'] = df_questions['Body'].apply(\n",
    "    lambda x: remove_by_tag(x, adjective_tag_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:22.797562Z",
     "start_time": "2021-05-27T11:27:22.794860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'looking way obtain value \\x8f\\x80 , challenge. specifically , using ways involve using constants like m_pi , number program tests ways know inline assembly version , theory , option , though clearly portable. included baseline compare versions. tests , built-ins , * atan( ) version gcc . , atan( ) constant. -fno-builtin specified , atan2( , - ) version fastest. testing program ( pitimes. ) : #include <math.> #include <stdio.> #include <time.> #define iters 10000000 #define testwith( ) { diff = . ; \\\\ time1 = clock( ) ; \\\\ ( = ; iters ; ++ ) \\\\ += ( ) - m_pi ; \\\\ time2 = clock( ) ; \\\\ printf( \" % \\\\=> % , time => % \\\\ \" , # , diff , diffclock( time2 , time1 ) ) ; \\\\ } inline diffclock( clock_t time1 , clock_t time0 ) { return ( ) ( - time0 ) / clocks_per_sec ; } int main( ) { int ; clock_t time1 , time2 ; diff ; / * warmup. atan2 case catches gcc \\' folding ( would * optimise ` ` * atan( ) - m_pi \\' \\' no-op ) , * */ testwith( * atan( ) ) testwith( * atan2( , ) ) #if __gnuc__ ) &&amp ; ( defined( __i386__ ) &#124 ; &#124 ; defined( __amd64__ ) ) extern fldpi( ) ; testwith( fldpi( ) ) #endif * tests start here. */ testwith( atan2( , - ) ) testwith( acos( - ) ) testwith( * asin( ) ) testwith( * atan2( , ) ) testwith( * atan( ) ) return ; } inline assembly stuff ( fldpi. ) work systems : fldpi( ) { pi ; asm( \" \" : = \" ( pi ) ) ; return pi ; } build builds configurations testing ( build.sh ) : # ! / bin/sh gcc -o3 -wall - -m32 fldpi. gcc -o3 -wall - -m64 fldpi. gcc -o3 -wall -ffast-math -m32 -of pitimes. gcc -o3 -wall -m32 -of pitimes. -lm gcc -o3 -wall -fno-builtin -m32 -of pitimes. -lm gcc -o3 -wall -ffast-math -m64 -of pitimes. -lm gcc -o3 -wall -m64 -of pitimes. -lm gcc -o3 -wall -fno-builtin -m64 -of pitimes. -lm apart testing compiler flags ( compared 32-bit optimizations ) , also tried switching order tests around. still , atan2( , - ) version still comes every time .'"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Stemming / Lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Stemming et la Lemmatisation sont des opérations qui:\n",
    "- peuvent améliorer votre temps de calcul en réduisant votre vocabulaire\n",
    "- aider à généraliser plus facilement en regroupant les mots (ex: \"suis\", \"sont\", \"être\", etc. seront transformés en \"être\" pour la lemmatisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je n'ai pas choisi d'utiliser le stemming ici, mais l'on doit toujours envisager cette alternative car elle est beaucoup moins coûteuse.\n",
    "\n",
    "Le stemming est le processus de réduction des mots fléchis à leur racine mot, base ou forme de racine - généralement une forme de mot écrit (\"fishing\", \"fished\", and \"fisher\" à la racine \"fish\"). Il fonctionne généralement en supprimant l'affixe d'un mot. Un affixe peut être un suffixe ou un préfixe (par exemple «-ed», «-ing», etc.). C'est simple mais ne fonctionnera pas lorsque le mot est \"irrégulier\" (\"ran\" et \"run\"). C'est une opération plus simple que la lemmatisation, qui peut suffire dans certains cas, mais peut faire trop d'erreurs dans d'autres cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:22.809188Z",
     "start_time": "2021-05-27T11:27:22.798638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program  :  program\n",
      "programs  :  program\n",
      "programer  :  program\n",
      "programing  :  program\n",
      "programers  :  program\n"
     ]
    }
   ],
   "source": [
    "words = [\"program\", \"programs\", \"programer\", \"programing\", \"programers\"]\n",
    "  \n",
    "for w in words:\n",
    "    print(w, \" : \", stemmer.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:22.817921Z",
     "start_time": "2021-05-27T11:27:22.810232Z"
    }
   },
   "outputs": [],
   "source": [
    "def stem_text(text):\n",
    "    \"\"\"Stem the text\"\"\"\n",
    "    words = nltk.word_tokenize(text) # tokenize the text then return a list of tuple (token, nltk_tag)\n",
    "    stem_text = []\n",
    "    for word in words:\n",
    "        stem_text.append(stemmer.stem(word)) # Stem each words\n",
    "    return \" \".join(stem_text) # Return the text untokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:22.826287Z",
     "start_time": "2021-05-27T11:27:22.818971Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# df_questions['Title'] = df_questions['Title'].apply(lambda x: stem_text(x)) \n",
    "# df_questions['Body'] = df_questions['Body'].apply(lambda x: stem_text(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Lemmatization\n",
    "\n",
    "Comme dit au début, la lemmatisation est le processus de remplacement d'un mot par son lemma (forme canonique ou forme dictionnaire). Mais dans certains cas, un lemmatiseur peut ne pas être en mesure de trouver la bonne racine si vous ne précisez pas le type de mot comme vous pouvez le voir ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:24.009842Z",
     "start_time": "2021-05-27T11:27:22.827343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strip\n",
      "stripe\n",
      "are\n",
      "be\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"stripes\", \"v\"))\n",
    "print(lemmatizer.lemmatize(\"stripes\", \"n\"))  \n",
    "print(lemmatizer.lemmatize(\"are\"))\n",
    "print(lemmatizer.lemmatize(\"are\", \"v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une façon de contourner ce problème consiste à utiliser un marqueur et à passer le type de mot dans la fonction lemmatize. MAIS c'est vraiment coûteux. La mise en tige ou une simple lemmatisation à cet égard est bien plus efficace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:24.014555Z",
     "start_time": "2021-05-27T11:27:24.010867Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    \"\"\"Lemmatize the text by using tag \"\"\"\n",
    "    \n",
    "    tokens_tagged = nltk.pos_tag(nltk.word_tokenize(text))  # tokenize the text then return a list of tuple (token, nltk_tag)\n",
    "    lemmatized_text = []\n",
    "    for word, tag in tokens_tagged:\n",
    "        if tag.startswith('J'):\n",
    "            lemmatized_text.append(lemmatizer.lemmatize(word,'a')) # Lemmatisze adjectives. Not doing anything since we remove all adjective\n",
    "        elif tag.startswith('V'):\n",
    "            lemmatized_text.append(lemmatizer.lemmatize(word,'v')) # Lemmatisze verbs\n",
    "        elif tag.startswith('N'):\n",
    "            lemmatized_text.append(lemmatizer.lemmatize(word,'n')) # Lemmatisze nouns\n",
    "        elif tag.startswith('R'):\n",
    "            lemmatized_text.append(lemmatizer.lemmatize(word,'r')) # Lemmatisze adverbs\n",
    "        else:\n",
    "            lemmatized_text.append(lemmatizer.lemmatize(word)) # If no tags has been found, perform a non specific lemmatization\n",
    "    return \" \".join(lemmatized_text) # Return the text untokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:26.439659Z",
     "start_time": "2021-05-27T11:27:24.015712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.98 s, sys: 11.3 ms, total: 2.99 s\n",
      "Wall time: 2.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_questions['Title'] = df_questions['Title'].apply(lambda x: lemmatize_text(x)) \n",
    "df_questions['Body'] = df_questions['Body'].apply(lambda x: lemmatize_text(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:26.443799Z",
     "start_time": "2021-05-27T11:27:26.440753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"look way obtain value \\x8f\\x80 , challenge . specifically , use way involve use constant like m_pi , number program test way know inline assembly version , theory , option , though clearly portable . include baseline compare version . test , built-ins , * atan ( ) version gcc . , atan ( ) constant . -fno-builtin specify , atan2 ( , - ) version fast . test program ( pitimes . ) : # include < math. > # include < stdio. > # include < time. > # define iters 10000000 # define testwith ( ) { diff = . ; \\\\ time1 = clock ( ) ; \\\\ ( = ; iters ; ++ ) \\\\ += ( ) - m_pi ; \\\\ time2 = clock ( ) ; \\\\ printf ( `` % \\\\= > % , time = > % \\\\ `` , # , diff , diffclock ( time2 , time1 ) ) ; \\\\ } inline diffclock ( clock_t time1 , clock_t time0 ) { return ( ) ( - time0 ) / clocks_per_sec ; } int main ( ) { int ; clock_t time1 , time2 ; diff ; / * warmup . atan2 case catch gcc ' folding ( would * optimise ` ` * atan ( ) - m_pi ' ' no-op ) , * * / testwith ( * atan ( ) ) testwith ( * atan2 ( , ) ) # if __gnuc__ ) & & amp ; ( define ( __i386__ ) & # 124 ; & # 124 ; define ( __amd64__ ) ) extern fldpi ( ) ; testwith ( fldpi ( ) ) # endif * test start here . * / testwith ( atan2 ( , - ) ) testwith ( acos ( - ) ) testwith ( * asin ( ) ) testwith ( * atan2 ( , ) ) testwith ( * atan ( ) ) return ; } inline assembly stuff ( fldpi . ) work system : fldpi ( ) { pi ; asm ( `` `` : = `` ( pi ) ) ; return pi ; } build build configuration test ( build.sh ) : # ! / bin/sh gcc -o3 -wall - -m32 fldpi . gcc -o3 -wall - -m64 fldpi . gcc -o3 -wall -ffast-math -m32 -of pitimes . gcc -o3 -wall -m32 -of pitimes . -lm gcc -o3 -wall -fno-builtin -m32 -of pitimes . -lm gcc -o3 -wall -ffast-math -m64 -of pitimes . -lm gcc -o3 -wall -m64 -of pitimes . -lm gcc -o3 -wall -fno-builtin -m64 -of pitimes . -lm apart test compiler flag ( compare 32-bit optimization ) , also try switch order test around . still , atan2 ( , - ) version still come every time .\""
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Body'][11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'utilisation du titre et du corps en même temps donne de bien meilleurs résultats pour la détection des sujets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:26.458090Z",
     "start_time": "2021-05-27T11:27:26.444991Z"
    }
   },
   "outputs": [],
   "source": [
    "df_questions['Text'] = df_questions['Title'] + ' ' + df_questions['Body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Exportation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T11:27:26.478700Z",
     "start_time": "2021-05-27T11:27:26.459138Z"
    }
   },
   "outputs": [],
   "source": [
    "df_questions.to_csv('df_questions_fullclean.csv', encoding='utf-8', errors='surrogatepass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}